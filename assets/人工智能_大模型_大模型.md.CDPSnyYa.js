import{_ as s,c as n,o as e,ae as p}from"./chunks/framework.rTUm5mJw.js";const u=JSON.parse('{"title":"大模型","description":"","frontmatter":{},"headers":[],"relativePath":"人工智能/大模型/大模型.md","filePath":"人工智能/大模型/大模型.md"}'),t={name:"人工智能/大模型/大模型.md"};function i(l,a,r,o,h,d){return e(),n("div",null,a[0]||(a[0]=[p(`<h1 id="大模型" tabindex="-1">大模型 <a class="header-anchor" href="#大模型" aria-label="Permalink to &quot;大模型&quot;">​</a></h1><h2 id="大模型相关论文pdf汇总" tabindex="-1">大模型相关论文PDF汇总 <a class="header-anchor" href="#大模型相关论文pdf汇总" aria-label="Permalink to &quot;大模型相关论文PDF汇总&quot;">​</a></h2><h3 id="大名鼎鼎的transformer" tabindex="-1">大名鼎鼎的Transformer <a class="header-anchor" href="#大名鼎鼎的transformer" aria-label="Permalink to &quot;大名鼎鼎的Transformer&quot;">​</a></h3><ul><li>标题： Attention Is All You Need</li><li>中文标题： 注意力是你所需要的一切</li><li>发表时间： 2017年</li></ul><h3 id="cv领域的新基石-vision-transformer" tabindex="-1">CV领域的新基石： Vision Transformer <a class="header-anchor" href="#cv领域的新基石-vision-transformer" aria-label="Permalink to &quot;CV领域的新基石： Vision Transformer&quot;">​</a></h3><ul><li>标题： An Image Is Worth 16X16 Words： Transformers for Image Recognition At Scale</li><li>中文标题： 一张图片等价于16x16大小的字：将Transformer用于图像识别</li><li>发表时间： 2020年10月</li><li>论文地址： <a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noreferrer">https://arxiv.org/abs/2010.11929</a></li></ul><h3 id="文生图、文生视频的基石-diffusion-transformer" tabindex="-1">文生图、文生视频的基石：Diffusion Transformer <a class="header-anchor" href="#文生图、文生视频的基石-diffusion-transformer" aria-label="Permalink to &quot;文生图、文生视频的基石：Diffusion Transformer&quot;">​</a></h3><ul><li>标题： Scalsble Diffusion Models with Transformers （DiT）</li><li>中文标题： 基于Transformers的可扩展的扩散模型</li><li>发表时间： 2022年12月</li><li>地址： <a href="https://arxiv.org/pdf/2212.09748" target="_blank" rel="noreferrer">https://arxiv.org/pdf/2212.09748</a></li></ul><h3 id="分割一切大模型" tabindex="-1">分割一切大模型 <a class="header-anchor" href="#分割一切大模型" aria-label="Permalink to &quot;分割一切大模型&quot;">​</a></h3><ul><li>标题： Segment Anything</li><li>中文标题： 分割一切</li></ul><h3 id="开源文生视频-stable-video-diffusion" tabindex="-1">开源文生视频： Stable Video Diffusion <a class="header-anchor" href="#开源文生视频-stable-video-diffusion" aria-label="Permalink to &quot;开源文生视频： Stable Video Diffusion&quot;">​</a></h3><ul><li>发布时间： 2023年11月</li></ul><h3 id="什么是微调" tabindex="-1">什么是微调？ <a class="header-anchor" href="#什么是微调" aria-label="Permalink to &quot;什么是微调？&quot;">​</a></h3><p>从头开始训练模型，成本高昂。 对所有的参数进行微调，是低效的。 固定前面的层，只微调接近下游的那几层参数，效果又不好。 将高维映射到低维，然后经过一个线性层，再从低维还原到高维。</p><h3 id="什么是强化学习" tabindex="-1">什么是强化学习？ <a class="header-anchor" href="#什么是强化学习" aria-label="Permalink to &quot;什么是强化学习？&quot;">​</a></h3><p>通过与环境交互，根据反馈来学习最佳行为。 智能体评估当前的状态，采取相应的动作，根据动作的正确与否得到奖励或惩罚。 智能体通过与环境的互动，学习到一个策略，使奖励最大化。</p><h3 id="google-io-2024发布内容简介" tabindex="-1">Google IO 2024发布内容简介 <a class="header-anchor" href="#google-io-2024发布内容简介" aria-label="Permalink to &quot;Google IO 2024发布内容简介&quot;">​</a></h3><p>基本围绕AI。Veo视频生成模型。Gemini 大模型。 Agent工具。AI辅助编程工具等。</p><h2 id="大模型文件后缀名及其含义" tabindex="-1">大模型文件后缀名及其含义 <a class="header-anchor" href="#大模型文件后缀名及其含义" aria-label="Permalink to &quot;大模型文件后缀名及其含义&quot;">​</a></h2><p>（1） safetensors</p><p>这是由 Hugging Face 推出的一种新型安全模型存储格式，特别关注模型安全性、隐私保护和快速加载。它仅包含模型的权重参数，而不包括执行代码，这样可以减少模型文件大小，提高加载速度。</p><p>（2） ckpt</p><p>PyTorch Lightning 框架采用的模型存储格式。它不仅包含了模型参数，还包括优化器状态以及可能的训练元数据信息，使得用户可以无缝地恢复训练或执行推理。</p><p>（3） bin</p><p>通常是一种通用的二进制格式文件，它可以用来存储任意类型的数据。但在某些情况下可用于存储原始二进制权重数据，加载时需额外处理。</p><p>（4） pth</p><p>是 PyTorch 中用于保存模型状态的标准格式。方便模型的持久化和复用，支持完整模型结构和参数的保存与恢复。</p><h2 id="huggingface" tabindex="-1">Huggingface <a class="header-anchor" href="#huggingface" aria-label="Permalink to &quot;Huggingface&quot;">​</a></h2><h3 id="hugging-face镜像站" tabindex="-1">Hugging Face镜像站 <a class="header-anchor" href="#hugging-face镜像站" aria-label="Permalink to &quot;Hugging Face镜像站&quot;">​</a></h3><p>国内网络环境无法使用Huggingface，可以使用其镜像站 ：<a href="https://hf-mirror.com" target="_blank" rel="noreferrer">https://hf-mirror.com</a></p><p>要下载镜像站的大模型文件，有两种方式。</p><p>方法一： 直接在网页下载</p><p>打开大模型页面 <a href="https://hf-mirror.com/%E7%94%A8%E6%88%B7%E5%90%8D/%E6%A8%A1%E5%9E%8B%E5%90%8D" target="_blank" rel="noreferrer">https://hf-mirror.com/用户名/模型名</a> ，进入files标签，直接下载里面的文件。</p><p>方法二： 使用命令行工具</p><p>首先安装命令行工具Python包：</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  -U</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  huggingface_hub</span></span></code></pre></div><p>然后设置环境变量 HF_ENDPOINT = &quot;<a href="https://hf-mirror.com" target="_blank" rel="noreferrer">https://hf-mirror.com</a>&quot;</p><p>然后下载模型：</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">huggingface-cli</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  download</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --resume-download</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  gpt2</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --local-dir</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  gpt2</span></span></code></pre></div><p>下载数据集：</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">huggingface-cli</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  download</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --repo-type</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  drataset</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --esume-download</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  wikitext</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --local-dir</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  wikitext</span></span></code></pre></div><p>注意，有些项目需要登录Huggingface Face源站获取Token才能下载。</p><h3 id="指定本地路径-避免反复下载" tabindex="-1">指定本地路径，避免反复下载 <a class="header-anchor" href="#指定本地路径-避免反复下载" aria-label="Permalink to &quot;指定本地路径，避免反复下载&quot;">​</a></h3><p>大模型文件很大，每次都重新下载费时费力，因此可以指定本地路径。from_pretrain 函数可以接收一个模型的id，也可以接收模型的本地存储路径。</p><p>先在网络较好时将HF上的整个文件夹下载下来，然后推理的时候指定本地的这个文件夹即可。</p><h2 id="强化学习" tabindex="-1">强化学习 <a class="header-anchor" href="#强化学习" aria-label="Permalink to &quot;强化学习&quot;">​</a></h2><ul><li>提示学习</li></ul><p>插槽式、类似于插值字符串</p><ul><li>语境学习</li></ul><p>带有情感极性的句子示例</p><ul><li>高效模型微调LoRA</li></ul><p>在原本矩阵旁边添加低秩矩阵 在残差连接添加适配层作为可训练参数</p><ul><li>低秩矩阵</li></ul><p>秩序：矩阵中最大不相关向量的个数，可以理解为有秩序的程度。</p><p>矩阵的秩的度量其实就是矩阵的行列之间的相关性。如果矩阵的各行或列是线性无关的，矩阵就是满秩的。非零元素的行数或列数决定了秩的多少。</p><p>低秩矩阵：矩阵的秩相对矩阵的行数或列数而言很小。</p><p>图像处理中，秩可以理解为包含信息的丰富程度。如果一张草原图全是草，那么就是低秩。</p><ul><li>稀疏矩阵</li></ul><p>稀疏是指矩阵中非零元素的个数少。</p><ul><li>思维链</li></ul><p>解题思路和步骤输入给模型，使得模型不仅有结果，还有中间步骤。</p><h2 id="深度学习" tabindex="-1">深度学习 <a class="header-anchor" href="#深度学习" aria-label="Permalink to &quot;深度学习&quot;">​</a></h2><h2 id="深度学习的基本概念" tabindex="-1">深度学习的基本概念 <a class="header-anchor" href="#深度学习的基本概念" aria-label="Permalink to &quot;深度学习的基本概念&quot;">​</a></h2><h3 id="残差连接" tabindex="-1">残差连接 <a class="header-anchor" href="#残差连接" aria-label="Permalink to &quot;残差连接&quot;">​</a></h3><p>将输入多次处理后，再和最开始的那个输入做一次加法运算</p><h3 id="归一化" tabindex="-1">归一化 <a class="header-anchor" href="#归一化" aria-label="Permalink to &quot;归一化&quot;">​</a></h3><p>使一组数据限定在一个范围内，如0~1或-1~1，以加快收敛</p><h3 id="线性层" tabindex="-1">线性层 <a class="header-anchor" href="#线性层" aria-label="Permalink to &quot;线性层&quot;">​</a></h3><p>加入一组权重，然后不断训练调整</p><h3 id="softmax" tabindex="-1">SoftMax <a class="header-anchor" href="#softmax" aria-label="Permalink to &quot;SoftMax&quot;">​</a></h3><p>将一组值转为一组概率，总和为1</p><h3 id="激活函数" tabindex="-1">激活函数 <a class="header-anchor" href="#激活函数" aria-label="Permalink to &quot;激活函数&quot;">​</a></h3><p>增加非线性，如果没有激活函数，就算层再多跟一层也没区别。目前最常用的是ReLu。</p><h3 id="epoch" tabindex="-1">epoch <a class="header-anchor" href="#epoch" aria-label="Permalink to &quot;epoch&quot;">​</a></h3><p>把整个数据集遍历一次称为一个epoch。推荐每运行完一个epoch就保存一次记录，这样就有更多的模型可供选择。</p><h3 id="repeat" tabindex="-1">repeat <a class="header-anchor" href="#repeat" aria-label="Permalink to &quot;repeat&quot;">​</a></h3><p>单张图片的重复遍历次数。在当前的epoch中，每张图片被遍历的次数。</p><h3 id="batch-size" tabindex="-1">batch-size <a class="header-anchor" href="#batch-size" aria-label="Permalink to &quot;batch-size&quot;">​</a></h3><p>批次大小。较大的批次训练速度更快，但需要更大的显存，需要更多的批次才能收敛。较小的batch size训练较慢，但显存占用更小，模型收敛的更快。</p><h3 id="过拟合和欠拟合的最通俗解释" tabindex="-1">过拟合和欠拟合的最通俗解释 <a class="header-anchor" href="#过拟合和欠拟合的最通俗解释" aria-label="Permalink to &quot;过拟合和欠拟合的最通俗解释&quot;">​</a></h3><p>欠拟合：没学会。 过拟合：学会了，但是学痴了，但能举一反三。</p><h2 id="pytorch" tabindex="-1">PyTorch <a class="header-anchor" href="#pytorch" aria-label="Permalink to &quot;PyTorch&quot;">​</a></h2><h3 id="pytorch相对numpy的优势" tabindex="-1">PyTorch相对Numpy的优势 <a class="header-anchor" href="#pytorch相对numpy的优势" aria-label="Permalink to &quot;PyTorch相对Numpy的优势&quot;">​</a></h3><p>PyTorch和Numpy的数组可以互相转换，本质上并无区别。PyTorch相对于Numpy的优势在于：</p><ul><li>支持GPU并行加速</li><li>自动微分</li></ul><p>所以，PyTorch 比 Numpy 快，而 Numpy 又比 Python 原生数组快！</p><h3 id="将张量放入gpu环境" tabindex="-1">将张量放入GPU环境 <a class="header-anchor" href="#将张量放入gpu环境" aria-label="Permalink to &quot;将张量放入GPU环境&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>import torch </span></span>
<span class="line"><span>print(torch.__version__)# torch版本</span></span>
<span class="line"><span>print(torch.version.cuda) #cuda版本</span></span>
<span class="line"><span>print(torch.cuda.is_available()) #cuda是否可用</span></span></code></pre></div><table tabindex="0"><thead><tr><th>代码</th><th>注释</th></tr></thead><tbody><tr><td>device = torch.device(&quot;cuda&quot;)</td><td>使用GPU环境</td></tr><tr><td>device = torch.device(&quot;cpu&quot;)</td><td>使用CPU环境</td></tr><tr><td>A.device</td><td>判断对象在哪个环节</td></tr><tr><td>A= A.to(device)</td><td>放入device中</td></tr><tr><td>A.cpu().device</td><td>放入CPU中</td></tr></tbody></table><p>torch.tensor(1.0) #标量 torch.tensor([[1.0,1.0],[1.0,1.0]])#二维数组 (2,2)</p><h2 id="张量" tabindex="-1">张量 <a class="header-anchor" href="#张量" aria-label="Permalink to &quot;张量&quot;">​</a></h2><h3 id="张量简介" tabindex="-1">张量简介 <a class="header-anchor" href="#张量简介" aria-label="Permalink to &quot;张量简介&quot;">​</a></h3><p>张量是PyTorch等深度学习框架中最基本的数据结构。张量的本质是多维数组，可以是一维的向量、二维的矩阵、三维的数组。</p><h3 id="张量的元素类型" tabindex="-1">张量的元素类型 <a class="header-anchor" href="#张量的元素类型" aria-label="Permalink to &quot;张量的元素类型&quot;">​</a></h3><table tabindex="0"><thead><tr><th>类型</th><th>CPU表示</th><th>GPU表示</th></tr></thead><tbody><tr><td>32位短整型</td><td>torch.IntTensor</td><td>torch.cuda.intTensor</td></tr><tr><td>64位长整型</td><td>torch.LongTensor</td><td>torch.cuda.LongTensor</td></tr><tr><td>单精度浮点型</td><td>torch.FloatTensor</td><td>torch.cuda.FloatTensor</td></tr><tr><td>双精度浮点型</td><td>torch.DoubleTensor</td><td>torch.cuda.DoubleTensor</td></tr></tbody></table><h3 id="特殊的张量" tabindex="-1">特殊的张量 <a class="header-anchor" href="#特殊的张量" aria-label="Permalink to &quot;特殊的张量&quot;">​</a></h3><table tabindex="0"><thead><tr><th>代码</th><th>作用</th></tr></thead><tbody><tr><td>torch.zeros(m,n)</td><td>mxn的全0矩阵</td></tr><tr><td>torch.ones(m,n)</td><td>mxn的全1矩阵</td></tr><tr><td>torch.eye(m,n)</td><td>mxn的单位矩阵，对角线为1，其它为0</td></tr><tr><td>torch.randn(m,n)</td><td>mxn的正态分布的随机数，0~1之间</td></tr><tr><td>torch.rand(m,n)</td><td>mxn的均匀分布的随机数，0~1之间</td></tr><tr><td>torch.Tensor([4,5,5,6])</td><td>根据数组字面量直接创建张量</td></tr><tr><td>torch.IntTensor([1,2])</td><td>指定数据类型</td></tr></tbody></table><p>索引操作 y = x[0, : ] 第1行</p><h3 id="张量和numpy数组的互转" tabindex="-1">张量和Numpy数组的互转 <a class="header-anchor" href="#张量和numpy数组的互转" aria-label="Permalink to &quot;张量和Numpy数组的互转&quot;">​</a></h3><p>Numpy转Tensor：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>arr = np.ones(5,3)</span></span>
<span class="line"><span>T  = torch.from_numpy(a)</span></span></code></pre></div><p>改变张量的形状</p><p>张量对象调用view()方法可以改变形状 ，例如：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>import torch </span></span>
<span class="line"><span>T1 = Torch.ones(3,8)</span></span>
<span class="line"><span>T2 = T1.view(4,6)</span></span></code></pre></div><p>也可以将某个维度的长度设置为-1，会自动计算：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>import torch </span></span>
<span class="line"><span>T1 = Torch.ones(3,8)</span></span>
<span class="line"><span>T2 = T1.view(-1 ,6)   # 第一维自动计算</span></span></code></pre></div><p>还有两个方法去掉或增加长度为1的维度：</p><ul><li>squeeze(T) ： 去掉长度为1的维度</li><li>unsqueeze(T) ： 增加长度为1的维度</li></ul><p>dataloader的参数</p><p>dataset 数据集 batch_size 批次大小，默认1</p><p>Epoch： 所有的样本都输入到模型中，称为一个epoch Iteration： 一个Batch的样本输入到模型中，称为一个Iteration batch_size： 一个批次的大小，一个Epoch=Batchsize*Iteration</p><p>DataLoader()的参数： dataset 数据集 batch_size 批次大小 shuffle 是否乱序 sampler 样本采样函数，一般无需设置 batch_sampler 批次采样函数，一般无需设置 num_workers 使用多进程读取数据，使用的进程数 collate_fn 整理一个批次数据的函数</p><p>Dataset 数据集 DataLoader 数据装载器</p><p>自建数据集： dataset = TensorDataset(torch.arange(1, 40)) dl = DataLoader(dataset, batch_size=10) # 批次大小10，因此有4个批次</p><h3 id="矩阵的乘法" tabindex="-1">矩阵的乘法 <a class="header-anchor" href="#矩阵的乘法" aria-label="Permalink to &quot;矩阵的乘法&quot;">​</a></h3><p>T1.matmul(T2) T1 @ T2 # 与上等价</p><p>神经网络和矩阵乘法的对应</p><p>神经网络和矩阵乘法的对应关系如下图所示：</p><pre><code>首先将输入展平为一个一维向量，中间的每条线对应着一个数值，这些数值组合起来就是一个矩阵，在深度学习中叫做权重。如果每个输入跟每个输出全部相连，就叫做全连接。
</code></pre><p>torch.nn torch.nn是神经网络工具箱，该工具箱建立于Autogard（主要有自动求导和梯度反向传播功能），提供了网络搭建的模组，优化器等一系列功能。</p><p>搭建一个神经网络的整体流程： 数组读取 定义模型 定义损失函数和优化器 模型训练 获取训练结果</p><p>Torch 运算 torch.item() 取出数据，注意，只有一个元素时才能用 T.numpy() 转为Numpy T.from_numpy() 从Numpy导入 T.view() 变形、重构尺寸，类 似Numpy的reshape变形 T.transpose(0,1) 行列交换</p><p>拼接stack torch.stack((A,B), dim=0) dim表示拼接方向</p><p>正向传播、反向传播</p><p>正向：由输入得到输出 反向：根据损失函数计算预测值与真实值之间的误差，计算每个节点对应的输入的梯度，最终得到参数的梯度信息。</p><p>梯度 为什么要算梯度？ 使得损失函数最小，梯度（斜率）为0 y.backward() 计算梯度 x.grad 获取梯度值</p><p>梯度下降法是一种致力于找到函数极值点的算法。所谓“训练”或“学习”就是改进模型参数，以便通过大量训练步骤将损失最小化。梯度下降法的思路很简单，就是沿着函数下降最快的方向改变模型参数，直到到达最低点。</p><p>超参数 超参数就是需要用户手工配置的参数。</p><p>学习率 Wi+1 = Wi - 学习率 x ▽Wi 学习率就是每次下降的幅度。太小，则需要很多轮迭代，浪费资源； 太大，则可能会跳过最小点</p><p>一个简单的神经网络示例</p><p>我们拿一个最简单的FNN网络来对经典数据集diabetes糖尿病数据集来进行分类预测。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>    import numpy as np	</span></span>
<span class="line"><span>    import torch</span></span>
<span class="line"><span>    import matplotlib.pyplot as plt</span></span>
<span class="line"><span>    from torch.utils.data import Dataset, DataLoader</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    # Prepare the dataset 准备数据集</span></span>
<span class="line"><span>    class DiabetesDateset(Dataset):</span></span>
<span class="line"><span>        # 加载数据集</span></span>
<span class="line"><span>        def __init__(self, filepath):</span></span>
<span class="line"><span>            xy = np.loadtxt(filepath, delimiter=&#39;,&#39;, dtype=np.float32, encoding=&#39;utf-8&#39;)</span></span>
<span class="line"><span>            self.len = xy.shape[0]  # shape[0]是矩阵的行数,shape[1]是矩阵的列数</span></span>
<span class="line"><span>            self.x_data = torch.from_numpy(xy[:, :-1])</span></span>
<span class="line"><span>            self.y_data = torch.from_numpy(xy[:, [-1]])</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>        # 获取数据索引</span></span>
<span class="line"><span>        def __getitem__(self, index):</span></span>
<span class="line"><span>            return self.x_data[index], self.y_data[index]</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>        # 获得数据总量</span></span>
<span class="line"><span>        def __len__(self):</span></span>
<span class="line"><span>            return self.len</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    dataset = DiabetesDateset(&#39;diabetes.csv&#39;)</span></span>
<span class="line"><span>    </span></span>
<span class="line"><span>    train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=2)  </span></span>
<span class="line"><span>    # num_workers为多线程</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    # Define the model   定义模型</span></span>
<span class="line"><span>    </span></span>
<span class="line"><span>    class FNNModel(torch.nn.Module):</span></span>
<span class="line"><span>        def __init__(self):</span></span>
<span class="line"><span>            super(FNNModel, self).__init__()</span></span>
<span class="line"><span>            self.linear1 = torch.nn.Linear(8, 6)  # 输入数据的特征有8个,也就是有8个维度,随后将其降维到6维</span></span>
<span class="line"><span>            self.linear2 = torch.nn.Linear(6, 4)  # 6维降到4维</span></span>
<span class="line"><span>            self.linear3 = torch.nn.Linear(4, 2)  # 4维降到2维</span></span>
<span class="line"><span>            self.linear4 = torch.nn.Linear(2, 1)  # 2w维降到1维</span></span>
<span class="line"><span>            self.sigmoid = torch.nn.Sigmoid()  # 可以视其为网络的一层,而不是简单的函数使用</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>        def forward(self, x):</span></span>
<span class="line"><span>            x = self.sigmoid(self.linear1(x))</span></span>
<span class="line"><span>            x = self.sigmoid(self.linear2(x))</span></span>
<span class="line"><span>            x = self.sigmoid(self.linear3(x))</span></span>
<span class="line"><span>            x = self.sigmoid(self.linear4(x))</span></span>
<span class="line"><span>            return x</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    model = FNNModel()</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    # Define the criterion and optimizer 定义优化和损失</span></span>
<span class="line"><span>    criterion = torch.nn.BCELoss(reduction=&#39;mean&#39;)  # 返回损失的平均值</span></span>
<span class="line"><span>    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    epoch_list = []</span></span>
<span class="line"><span>    loss_list = []</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    # Training  训练</span></span>
<span class="line"><span>    if __name__ == &#39;__main__&#39;: </span></span>
<span class="line"><span>        for epoch in range(100):</span></span>
<span class="line"><span>            # i是一个epoch中第几次迭代,一共756条数据,每个mini_batch为32,所以一个epoch需要迭代23次</span></span>
<span class="line"><span>            # data获取的数据为(x,y)</span></span>
<span class="line"><span>            loss_one_epoch = 0</span></span>
<span class="line"><span>            for i, data in enumerate(train_loader, 0):</span></span>
<span class="line"><span>                inputs, labels = data    # 输入实际</span></span>
<span class="line"><span>                y_pred = model(inputs)  #  预测输入</span></span>
<span class="line"><span>                loss = criterion(y_pred, labels)  # 预测实际</span></span>
<span class="line"><span>                loss_one_epoch += loss.item()</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>                optimizer.zero_grad()</span></span>
<span class="line"><span>                loss.backward()</span></span>
<span class="line"><span>                optimizer.step()</span></span>
<span class="line"><span>            loss_list.append(loss_one_epoch / 23)</span></span>
<span class="line"><span>            epoch_list.append(epoch)</span></span>
<span class="line"><span>            print(&#39;Epoch[{}/{}],loss:{:.6f}&#39;.format(epoch + 1, 100, loss_one_epoch / 23))</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>        # Drawing</span></span>
<span class="line"><span>        plt.plot(epoch_list, loss_list)</span></span>
<span class="line"><span>        plt.xlabel(&#39;epoch&#39;)</span></span>
<span class="line"><span>        plt.ylabel(&#39;loss&#39;)</span></span>
<span class="line"><span>        plt.show()</span></span></code></pre></div>`,132)]))}const m=s(t,[["render",i]]);export{u as __pageData,m as default};
