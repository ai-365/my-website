<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>大模型 | 我的个人博客网站</title>
    <meta name="description" content="个人博客网站">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/blog/assets/style.CSrVYZkW.css" as="style">
    <link rel="preload stylesheet" href="/blog/vp-icons.css" as="style">
    
    <script type="module" src="/blog/assets/app.CebyLLM_.js"></script>
    <link rel="preload" href="/blog/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/blog/assets/chunks/theme.BOSPpO_w.js">
    <link rel="modulepreload" href="/blog/assets/chunks/framework.rTUm5mJw.js">
    <link rel="modulepreload" href="/blog/assets/人工智能_大模型_大模型.md.CDPSnyYa.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-bd45b254><!--[--><!--]--><!--[--><span tabindex="-1" data-v-40f86efc></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-40f86efc>Skip to content</a><!--]--><!----><header class="VPNav" data-v-bd45b254 data-v-fb232767><div class="VPNavBar" data-v-fb232767 data-v-da0c6bb0><div class="wrapper" data-v-da0c6bb0><div class="container" data-v-da0c6bb0><div class="title" data-v-da0c6bb0><div class="VPNavBarTitle" data-v-da0c6bb0 data-v-dcd02d3b><a class="title" href="/blog/" data-v-dcd02d3b><!--[--><!--]--><!----><span data-v-dcd02d3b>我的个人博客网站</span><!--[--><!--]--></a></div></div><div class="content" data-v-da0c6bb0><div class="content-body" data-v-da0c6bb0><!--[--><!--]--><div class="VPNavBarSearch search" data-v-da0c6bb0><!----></div><!----><!----><div class="VPNavBarAppearance appearance" data-v-da0c6bb0 data-v-60d4da9a><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-60d4da9a data-v-dd4d226c data-v-27e5f2a7><span class="check" data-v-27e5f2a7><span class="icon" data-v-27e5f2a7><!--[--><span class="vpi-sun sun" data-v-dd4d226c></span><span class="vpi-moon moon" data-v-dd4d226c></span><!--]--></span></span></button></div><!----><div class="VPFlyout VPNavBarExtra extra" data-v-da0c6bb0 data-v-700cb35d data-v-ec49d971><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-ec49d971><span class="vpi-more-horizontal icon" data-v-ec49d971></span></button><div class="menu" data-v-ec49d971><div class="VPMenu" data-v-ec49d971 data-v-381ce922><!----><!--[--><!--[--><!----><div class="group" data-v-700cb35d><div class="item appearance" data-v-700cb35d><p class="label" data-v-700cb35d>Appearance</p><div class="appearance-action" data-v-700cb35d><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-700cb35d data-v-dd4d226c data-v-27e5f2a7><span class="check" data-v-27e5f2a7><span class="icon" data-v-27e5f2a7><!--[--><span class="vpi-sun sun" data-v-dd4d226c></span><span class="vpi-moon moon" data-v-dd4d226c></span><!--]--></span></span></button></div></div></div><!----><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-da0c6bb0 data-v-aa5c404b><span class="container" data-v-aa5c404b><span class="top" data-v-aa5c404b></span><span class="middle" data-v-aa5c404b></span><span class="bottom" data-v-aa5c404b></span></span></button></div></div></div></div><div class="divider" data-v-da0c6bb0><div class="divider-line" data-v-da0c6bb0></div></div></div><!----></header><div class="VPLocalNav empty fixed" data-v-bd45b254 data-v-1337b658><div class="container" data-v-1337b658><!----><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-1337b658 data-v-05f14d6b><button data-v-05f14d6b>Return to top</button><!----></div></div></div><!----><div class="VPContent" id="VPContent" data-v-bd45b254 data-v-d83a6a16><div class="VPDoc has-aside" data-v-d83a6a16 data-v-ddd4901f><!--[--><!--]--><div class="container" data-v-ddd4901f><div class="aside" data-v-ddd4901f><div class="aside-curtain" data-v-ddd4901f></div><div class="aside-container" data-v-ddd4901f><div class="aside-content" data-v-ddd4901f><div class="VPDocAside" data-v-ddd4901f data-v-9ff60a05><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-9ff60a05 data-v-7cf8e59d><div class="content" data-v-7cf8e59d><div class="outline-marker" data-v-7cf8e59d></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-7cf8e59d>On this page</div><ul class="VPDocOutlineItem root" data-v-7cf8e59d data-v-385136ab><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-9ff60a05></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-ddd4901f><div class="content-container" data-v-ddd4901f><!--[--><!--]--><main class="main" data-v-ddd4901f><div style="position:relative;" class="vp-doc _blog_%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD_%E5%A4%A7%E6%A8%A1%E5%9E%8B_%E5%A4%A7%E6%A8%A1%E5%9E%8B" data-v-ddd4901f><div><h1 id="大模型" tabindex="-1">大模型 <a class="header-anchor" href="#大模型" aria-label="Permalink to &quot;大模型&quot;">​</a></h1><h2 id="大模型相关论文pdf汇总" tabindex="-1">大模型相关论文PDF汇总 <a class="header-anchor" href="#大模型相关论文pdf汇总" aria-label="Permalink to &quot;大模型相关论文PDF汇总&quot;">​</a></h2><h3 id="大名鼎鼎的transformer" tabindex="-1">大名鼎鼎的Transformer <a class="header-anchor" href="#大名鼎鼎的transformer" aria-label="Permalink to &quot;大名鼎鼎的Transformer&quot;">​</a></h3><ul><li>标题： Attention Is All You Need</li><li>中文标题： 注意力是你所需要的一切</li><li>发表时间： 2017年</li></ul><h3 id="cv领域的新基石-vision-transformer" tabindex="-1">CV领域的新基石： Vision Transformer <a class="header-anchor" href="#cv领域的新基石-vision-transformer" aria-label="Permalink to &quot;CV领域的新基石： Vision Transformer&quot;">​</a></h3><ul><li>标题： An Image Is Worth 16X16 Words： Transformers for Image Recognition At Scale</li><li>中文标题： 一张图片等价于16x16大小的字：将Transformer用于图像识别</li><li>发表时间： 2020年10月</li><li>论文地址： <a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noreferrer">https://arxiv.org/abs/2010.11929</a></li></ul><h3 id="文生图、文生视频的基石-diffusion-transformer" tabindex="-1">文生图、文生视频的基石：Diffusion Transformer <a class="header-anchor" href="#文生图、文生视频的基石-diffusion-transformer" aria-label="Permalink to &quot;文生图、文生视频的基石：Diffusion Transformer&quot;">​</a></h3><ul><li>标题： Scalsble Diffusion Models with Transformers （DiT）</li><li>中文标题： 基于Transformers的可扩展的扩散模型</li><li>发表时间： 2022年12月</li><li>地址： <a href="https://arxiv.org/pdf/2212.09748" target="_blank" rel="noreferrer">https://arxiv.org/pdf/2212.09748</a></li></ul><h3 id="分割一切大模型" tabindex="-1">分割一切大模型 <a class="header-anchor" href="#分割一切大模型" aria-label="Permalink to &quot;分割一切大模型&quot;">​</a></h3><ul><li>标题： Segment Anything</li><li>中文标题： 分割一切</li></ul><h3 id="开源文生视频-stable-video-diffusion" tabindex="-1">开源文生视频： Stable Video Diffusion <a class="header-anchor" href="#开源文生视频-stable-video-diffusion" aria-label="Permalink to &quot;开源文生视频： Stable Video Diffusion&quot;">​</a></h3><ul><li>发布时间： 2023年11月</li></ul><h3 id="什么是微调" tabindex="-1">什么是微调？ <a class="header-anchor" href="#什么是微调" aria-label="Permalink to &quot;什么是微调？&quot;">​</a></h3><p>从头开始训练模型，成本高昂。 对所有的参数进行微调，是低效的。 固定前面的层，只微调接近下游的那几层参数，效果又不好。 将高维映射到低维，然后经过一个线性层，再从低维还原到高维。</p><h3 id="什么是强化学习" tabindex="-1">什么是强化学习？ <a class="header-anchor" href="#什么是强化学习" aria-label="Permalink to &quot;什么是强化学习？&quot;">​</a></h3><p>通过与环境交互，根据反馈来学习最佳行为。 智能体评估当前的状态，采取相应的动作，根据动作的正确与否得到奖励或惩罚。 智能体通过与环境的互动，学习到一个策略，使奖励最大化。</p><h3 id="google-io-2024发布内容简介" tabindex="-1">Google IO 2024发布内容简介 <a class="header-anchor" href="#google-io-2024发布内容简介" aria-label="Permalink to &quot;Google IO 2024发布内容简介&quot;">​</a></h3><p>基本围绕AI。Veo视频生成模型。Gemini 大模型。 Agent工具。AI辅助编程工具等。</p><h2 id="大模型文件后缀名及其含义" tabindex="-1">大模型文件后缀名及其含义 <a class="header-anchor" href="#大模型文件后缀名及其含义" aria-label="Permalink to &quot;大模型文件后缀名及其含义&quot;">​</a></h2><p>（1） safetensors</p><p>这是由 Hugging Face 推出的一种新型安全模型存储格式，特别关注模型安全性、隐私保护和快速加载。它仅包含模型的权重参数，而不包括执行代码，这样可以减少模型文件大小，提高加载速度。</p><p>（2） ckpt</p><p>PyTorch Lightning 框架采用的模型存储格式。它不仅包含了模型参数，还包括优化器状态以及可能的训练元数据信息，使得用户可以无缝地恢复训练或执行推理。</p><p>（3） bin</p><p>通常是一种通用的二进制格式文件，它可以用来存储任意类型的数据。但在某些情况下可用于存储原始二进制权重数据，加载时需额外处理。</p><p>（4） pth</p><p>是 PyTorch 中用于保存模型状态的标准格式。方便模型的持久化和复用，支持完整模型结构和参数的保存与恢复。</p><h2 id="huggingface" tabindex="-1">Huggingface <a class="header-anchor" href="#huggingface" aria-label="Permalink to &quot;Huggingface&quot;">​</a></h2><h3 id="hugging-face镜像站" tabindex="-1">Hugging Face镜像站 <a class="header-anchor" href="#hugging-face镜像站" aria-label="Permalink to &quot;Hugging Face镜像站&quot;">​</a></h3><p>国内网络环境无法使用Huggingface，可以使用其镜像站 ：<a href="https://hf-mirror.com" target="_blank" rel="noreferrer">https://hf-mirror.com</a></p><p>要下载镜像站的大模型文件，有两种方式。</p><p>方法一： 直接在网页下载</p><p>打开大模型页面 <a href="https://hf-mirror.com/%E7%94%A8%E6%88%B7%E5%90%8D/%E6%A8%A1%E5%9E%8B%E5%90%8D" target="_blank" rel="noreferrer">https://hf-mirror.com/用户名/模型名</a> ，进入files标签，直接下载里面的文件。</p><p>方法二： 使用命令行工具</p><p>首先安装命令行工具Python包：</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  -U</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  huggingface_hub</span></span></code></pre></div><p>然后设置环境变量 HF_ENDPOINT = &quot;<a href="https://hf-mirror.com" target="_blank" rel="noreferrer">https://hf-mirror.com</a>&quot;</p><p>然后下载模型：</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">huggingface-cli</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  download</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --resume-download</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  gpt2</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --local-dir</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  gpt2</span></span></code></pre></div><p>下载数据集：</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">huggingface-cli</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  download</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --repo-type</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  drataset</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --esume-download</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  wikitext</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --local-dir</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  wikitext</span></span></code></pre></div><p>注意，有些项目需要登录Huggingface Face源站获取Token才能下载。</p><h3 id="指定本地路径-避免反复下载" tabindex="-1">指定本地路径，避免反复下载 <a class="header-anchor" href="#指定本地路径-避免反复下载" aria-label="Permalink to &quot;指定本地路径，避免反复下载&quot;">​</a></h3><p>大模型文件很大，每次都重新下载费时费力，因此可以指定本地路径。from_pretrain 函数可以接收一个模型的id，也可以接收模型的本地存储路径。</p><p>先在网络较好时将HF上的整个文件夹下载下来，然后推理的时候指定本地的这个文件夹即可。</p><h2 id="强化学习" tabindex="-1">强化学习 <a class="header-anchor" href="#强化学习" aria-label="Permalink to &quot;强化学习&quot;">​</a></h2><ul><li>提示学习</li></ul><p>插槽式、类似于插值字符串</p><ul><li>语境学习</li></ul><p>带有情感极性的句子示例</p><ul><li>高效模型微调LoRA</li></ul><p>在原本矩阵旁边添加低秩矩阵 在残差连接添加适配层作为可训练参数</p><ul><li>低秩矩阵</li></ul><p>秩序：矩阵中最大不相关向量的个数，可以理解为有秩序的程度。</p><p>矩阵的秩的度量其实就是矩阵的行列之间的相关性。如果矩阵的各行或列是线性无关的，矩阵就是满秩的。非零元素的行数或列数决定了秩的多少。</p><p>低秩矩阵：矩阵的秩相对矩阵的行数或列数而言很小。</p><p>图像处理中，秩可以理解为包含信息的丰富程度。如果一张草原图全是草，那么就是低秩。</p><ul><li>稀疏矩阵</li></ul><p>稀疏是指矩阵中非零元素的个数少。</p><ul><li>思维链</li></ul><p>解题思路和步骤输入给模型，使得模型不仅有结果，还有中间步骤。</p><h2 id="深度学习" tabindex="-1">深度学习 <a class="header-anchor" href="#深度学习" aria-label="Permalink to &quot;深度学习&quot;">​</a></h2><h2 id="深度学习的基本概念" tabindex="-1">深度学习的基本概念 <a class="header-anchor" href="#深度学习的基本概念" aria-label="Permalink to &quot;深度学习的基本概念&quot;">​</a></h2><h3 id="残差连接" tabindex="-1">残差连接 <a class="header-anchor" href="#残差连接" aria-label="Permalink to &quot;残差连接&quot;">​</a></h3><p>将输入多次处理后，再和最开始的那个输入做一次加法运算</p><h3 id="归一化" tabindex="-1">归一化 <a class="header-anchor" href="#归一化" aria-label="Permalink to &quot;归一化&quot;">​</a></h3><p>使一组数据限定在一个范围内，如0~1或-1~1，以加快收敛</p><h3 id="线性层" tabindex="-1">线性层 <a class="header-anchor" href="#线性层" aria-label="Permalink to &quot;线性层&quot;">​</a></h3><p>加入一组权重，然后不断训练调整</p><h3 id="softmax" tabindex="-1">SoftMax <a class="header-anchor" href="#softmax" aria-label="Permalink to &quot;SoftMax&quot;">​</a></h3><p>将一组值转为一组概率，总和为1</p><h3 id="激活函数" tabindex="-1">激活函数 <a class="header-anchor" href="#激活函数" aria-label="Permalink to &quot;激活函数&quot;">​</a></h3><p>增加非线性，如果没有激活函数，就算层再多跟一层也没区别。目前最常用的是ReLu。</p><h3 id="epoch" tabindex="-1">epoch <a class="header-anchor" href="#epoch" aria-label="Permalink to &quot;epoch&quot;">​</a></h3><p>把整个数据集遍历一次称为一个epoch。推荐每运行完一个epoch就保存一次记录，这样就有更多的模型可供选择。</p><h3 id="repeat" tabindex="-1">repeat <a class="header-anchor" href="#repeat" aria-label="Permalink to &quot;repeat&quot;">​</a></h3><p>单张图片的重复遍历次数。在当前的epoch中，每张图片被遍历的次数。</p><h3 id="batch-size" tabindex="-1">batch-size <a class="header-anchor" href="#batch-size" aria-label="Permalink to &quot;batch-size&quot;">​</a></h3><p>批次大小。较大的批次训练速度更快，但需要更大的显存，需要更多的批次才能收敛。较小的batch size训练较慢，但显存占用更小，模型收敛的更快。</p><h3 id="过拟合和欠拟合的最通俗解释" tabindex="-1">过拟合和欠拟合的最通俗解释 <a class="header-anchor" href="#过拟合和欠拟合的最通俗解释" aria-label="Permalink to &quot;过拟合和欠拟合的最通俗解释&quot;">​</a></h3><p>欠拟合：没学会。 过拟合：学会了，但是学痴了，但能举一反三。</p><h2 id="pytorch" tabindex="-1">PyTorch <a class="header-anchor" href="#pytorch" aria-label="Permalink to &quot;PyTorch&quot;">​</a></h2><h3 id="pytorch相对numpy的优势" tabindex="-1">PyTorch相对Numpy的优势 <a class="header-anchor" href="#pytorch相对numpy的优势" aria-label="Permalink to &quot;PyTorch相对Numpy的优势&quot;">​</a></h3><p>PyTorch和Numpy的数组可以互相转换，本质上并无区别。PyTorch相对于Numpy的优势在于：</p><ul><li>支持GPU并行加速</li><li>自动微分</li></ul><p>所以，PyTorch 比 Numpy 快，而 Numpy 又比 Python 原生数组快！</p><h3 id="将张量放入gpu环境" tabindex="-1">将张量放入GPU环境 <a class="header-anchor" href="#将张量放入gpu环境" aria-label="Permalink to &quot;将张量放入GPU环境&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>import torch </span></span>
<span class="line"><span>print(torch.__version__)# torch版本</span></span>
<span class="line"><span>print(torch.version.cuda) #cuda版本</span></span>
<span class="line"><span>print(torch.cuda.is_available()) #cuda是否可用</span></span></code></pre></div><table tabindex="0"><thead><tr><th>代码</th><th>注释</th></tr></thead><tbody><tr><td>device = torch.device(&quot;cuda&quot;)</td><td>使用GPU环境</td></tr><tr><td>device = torch.device(&quot;cpu&quot;)</td><td>使用CPU环境</td></tr><tr><td>A.device</td><td>判断对象在哪个环节</td></tr><tr><td>A= A.to(device)</td><td>放入device中</td></tr><tr><td>A.cpu().device</td><td>放入CPU中</td></tr></tbody></table><p>torch.tensor(1.0) #标量 torch.tensor([[1.0,1.0],[1.0,1.0]])#二维数组 (2,2)</p><h2 id="张量" tabindex="-1">张量 <a class="header-anchor" href="#张量" aria-label="Permalink to &quot;张量&quot;">​</a></h2><h3 id="张量简介" tabindex="-1">张量简介 <a class="header-anchor" href="#张量简介" aria-label="Permalink to &quot;张量简介&quot;">​</a></h3><p>张量是PyTorch等深度学习框架中最基本的数据结构。张量的本质是多维数组，可以是一维的向量、二维的矩阵、三维的数组。</p><h3 id="张量的元素类型" tabindex="-1">张量的元素类型 <a class="header-anchor" href="#张量的元素类型" aria-label="Permalink to &quot;张量的元素类型&quot;">​</a></h3><table tabindex="0"><thead><tr><th>类型</th><th>CPU表示</th><th>GPU表示</th></tr></thead><tbody><tr><td>32位短整型</td><td>torch.IntTensor</td><td>torch.cuda.intTensor</td></tr><tr><td>64位长整型</td><td>torch.LongTensor</td><td>torch.cuda.LongTensor</td></tr><tr><td>单精度浮点型</td><td>torch.FloatTensor</td><td>torch.cuda.FloatTensor</td></tr><tr><td>双精度浮点型</td><td>torch.DoubleTensor</td><td>torch.cuda.DoubleTensor</td></tr></tbody></table><h3 id="特殊的张量" tabindex="-1">特殊的张量 <a class="header-anchor" href="#特殊的张量" aria-label="Permalink to &quot;特殊的张量&quot;">​</a></h3><table tabindex="0"><thead><tr><th>代码</th><th>作用</th></tr></thead><tbody><tr><td>torch.zeros(m,n)</td><td>mxn的全0矩阵</td></tr><tr><td>torch.ones(m,n)</td><td>mxn的全1矩阵</td></tr><tr><td>torch.eye(m,n)</td><td>mxn的单位矩阵，对角线为1，其它为0</td></tr><tr><td>torch.randn(m,n)</td><td>mxn的正态分布的随机数，0~1之间</td></tr><tr><td>torch.rand(m,n)</td><td>mxn的均匀分布的随机数，0~1之间</td></tr><tr><td>torch.Tensor([4,5,5,6])</td><td>根据数组字面量直接创建张量</td></tr><tr><td>torch.IntTensor([1,2])</td><td>指定数据类型</td></tr></tbody></table><p>索引操作 y = x[0, : ] 第1行</p><h3 id="张量和numpy数组的互转" tabindex="-1">张量和Numpy数组的互转 <a class="header-anchor" href="#张量和numpy数组的互转" aria-label="Permalink to &quot;张量和Numpy数组的互转&quot;">​</a></h3><p>Numpy转Tensor：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>arr = np.ones(5,3)</span></span>
<span class="line"><span>T  = torch.from_numpy(a)</span></span></code></pre></div><p>改变张量的形状</p><p>张量对象调用view()方法可以改变形状 ，例如：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>import torch </span></span>
<span class="line"><span>T1 = Torch.ones(3,8)</span></span>
<span class="line"><span>T2 = T1.view(4,6)</span></span></code></pre></div><p>也可以将某个维度的长度设置为-1，会自动计算：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>import torch </span></span>
<span class="line"><span>T1 = Torch.ones(3,8)</span></span>
<span class="line"><span>T2 = T1.view(-1 ,6)   # 第一维自动计算</span></span></code></pre></div><p>还有两个方法去掉或增加长度为1的维度：</p><ul><li>squeeze(T) ： 去掉长度为1的维度</li><li>unsqueeze(T) ： 增加长度为1的维度</li></ul><p>dataloader的参数</p><p>dataset 数据集 batch_size 批次大小，默认1</p><p>Epoch： 所有的样本都输入到模型中，称为一个epoch Iteration： 一个Batch的样本输入到模型中，称为一个Iteration batch_size： 一个批次的大小，一个Epoch=Batchsize*Iteration</p><p>DataLoader()的参数： dataset 数据集 batch_size 批次大小 shuffle 是否乱序 sampler 样本采样函数，一般无需设置 batch_sampler 批次采样函数，一般无需设置 num_workers 使用多进程读取数据，使用的进程数 collate_fn 整理一个批次数据的函数</p><p>Dataset 数据集 DataLoader 数据装载器</p><p>自建数据集： dataset = TensorDataset(torch.arange(1, 40)) dl = DataLoader(dataset, batch_size=10) # 批次大小10，因此有4个批次</p><h3 id="矩阵的乘法" tabindex="-1">矩阵的乘法 <a class="header-anchor" href="#矩阵的乘法" aria-label="Permalink to &quot;矩阵的乘法&quot;">​</a></h3><p>T1.matmul(T2) T1 @ T2 # 与上等价</p><p>神经网络和矩阵乘法的对应</p><p>神经网络和矩阵乘法的对应关系如下图所示：</p><pre><code>首先将输入展平为一个一维向量，中间的每条线对应着一个数值，这些数值组合起来就是一个矩阵，在深度学习中叫做权重。如果每个输入跟每个输出全部相连，就叫做全连接。
</code></pre><p>torch.nn torch.nn是神经网络工具箱，该工具箱建立于Autogard（主要有自动求导和梯度反向传播功能），提供了网络搭建的模组，优化器等一系列功能。</p><p>搭建一个神经网络的整体流程： 数组读取 定义模型 定义损失函数和优化器 模型训练 获取训练结果</p><p>Torch 运算 torch.item() 取出数据，注意，只有一个元素时才能用 T.numpy() 转为Numpy T.from_numpy() 从Numpy导入 T.view() 变形、重构尺寸，类 似Numpy的reshape变形 T.transpose(0,1) 行列交换</p><p>拼接stack torch.stack((A,B), dim=0) dim表示拼接方向</p><p>正向传播、反向传播</p><p>正向：由输入得到输出 反向：根据损失函数计算预测值与真实值之间的误差，计算每个节点对应的输入的梯度，最终得到参数的梯度信息。</p><p>梯度 为什么要算梯度？ 使得损失函数最小，梯度（斜率）为0 y.backward() 计算梯度 x.grad 获取梯度值</p><p>梯度下降法是一种致力于找到函数极值点的算法。所谓“训练”或“学习”就是改进模型参数，以便通过大量训练步骤将损失最小化。梯度下降法的思路很简单，就是沿着函数下降最快的方向改变模型参数，直到到达最低点。</p><p>超参数 超参数就是需要用户手工配置的参数。</p><p>学习率 Wi+1 = Wi - 学习率 x ▽Wi 学习率就是每次下降的幅度。太小，则需要很多轮迭代，浪费资源； 太大，则可能会跳过最小点</p><p>一个简单的神经网络示例</p><p>我们拿一个最简单的FNN网络来对经典数据集diabetes糖尿病数据集来进行分类预测。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>    import numpy as np	</span></span>
<span class="line"><span>    import torch</span></span>
<span class="line"><span>    import matplotlib.pyplot as plt</span></span>
<span class="line"><span>    from torch.utils.data import Dataset, DataLoader</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    # Prepare the dataset 准备数据集</span></span>
<span class="line"><span>    class DiabetesDateset(Dataset):</span></span>
<span class="line"><span>        # 加载数据集</span></span>
<span class="line"><span>        def __init__(self, filepath):</span></span>
<span class="line"><span>            xy = np.loadtxt(filepath, delimiter=&#39;,&#39;, dtype=np.float32, encoding=&#39;utf-8&#39;)</span></span>
<span class="line"><span>            self.len = xy.shape[0]  # shape[0]是矩阵的行数,shape[1]是矩阵的列数</span></span>
<span class="line"><span>            self.x_data = torch.from_numpy(xy[:, :-1])</span></span>
<span class="line"><span>            self.y_data = torch.from_numpy(xy[:, [-1]])</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>        # 获取数据索引</span></span>
<span class="line"><span>        def __getitem__(self, index):</span></span>
<span class="line"><span>            return self.x_data[index], self.y_data[index]</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>        # 获得数据总量</span></span>
<span class="line"><span>        def __len__(self):</span></span>
<span class="line"><span>            return self.len</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    dataset = DiabetesDateset(&#39;diabetes.csv&#39;)</span></span>
<span class="line"><span>    </span></span>
<span class="line"><span>    train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=2)  </span></span>
<span class="line"><span>    # num_workers为多线程</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    # Define the model   定义模型</span></span>
<span class="line"><span>    </span></span>
<span class="line"><span>    class FNNModel(torch.nn.Module):</span></span>
<span class="line"><span>        def __init__(self):</span></span>
<span class="line"><span>            super(FNNModel, self).__init__()</span></span>
<span class="line"><span>            self.linear1 = torch.nn.Linear(8, 6)  # 输入数据的特征有8个,也就是有8个维度,随后将其降维到6维</span></span>
<span class="line"><span>            self.linear2 = torch.nn.Linear(6, 4)  # 6维降到4维</span></span>
<span class="line"><span>            self.linear3 = torch.nn.Linear(4, 2)  # 4维降到2维</span></span>
<span class="line"><span>            self.linear4 = torch.nn.Linear(2, 1)  # 2w维降到1维</span></span>
<span class="line"><span>            self.sigmoid = torch.nn.Sigmoid()  # 可以视其为网络的一层,而不是简单的函数使用</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>        def forward(self, x):</span></span>
<span class="line"><span>            x = self.sigmoid(self.linear1(x))</span></span>
<span class="line"><span>            x = self.sigmoid(self.linear2(x))</span></span>
<span class="line"><span>            x = self.sigmoid(self.linear3(x))</span></span>
<span class="line"><span>            x = self.sigmoid(self.linear4(x))</span></span>
<span class="line"><span>            return x</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    model = FNNModel()</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    # Define the criterion and optimizer 定义优化和损失</span></span>
<span class="line"><span>    criterion = torch.nn.BCELoss(reduction=&#39;mean&#39;)  # 返回损失的平均值</span></span>
<span class="line"><span>    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    epoch_list = []</span></span>
<span class="line"><span>    loss_list = []</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    # Training  训练</span></span>
<span class="line"><span>    if __name__ == &#39;__main__&#39;: </span></span>
<span class="line"><span>        for epoch in range(100):</span></span>
<span class="line"><span>            # i是一个epoch中第几次迭代,一共756条数据,每个mini_batch为32,所以一个epoch需要迭代23次</span></span>
<span class="line"><span>            # data获取的数据为(x,y)</span></span>
<span class="line"><span>            loss_one_epoch = 0</span></span>
<span class="line"><span>            for i, data in enumerate(train_loader, 0):</span></span>
<span class="line"><span>                inputs, labels = data    # 输入实际</span></span>
<span class="line"><span>                y_pred = model(inputs)  #  预测输入</span></span>
<span class="line"><span>                loss = criterion(y_pred, labels)  # 预测实际</span></span>
<span class="line"><span>                loss_one_epoch += loss.item()</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>                optimizer.zero_grad()</span></span>
<span class="line"><span>                loss.backward()</span></span>
<span class="line"><span>                optimizer.step()</span></span>
<span class="line"><span>            loss_list.append(loss_one_epoch / 23)</span></span>
<span class="line"><span>            epoch_list.append(epoch)</span></span>
<span class="line"><span>            print(&#39;Epoch[{}/{}],loss:{:.6f}&#39;.format(epoch + 1, 100, loss_one_epoch / 23))</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>        # Drawing</span></span>
<span class="line"><span>        plt.plot(epoch_list, loss_list)</span></span>
<span class="line"><span>        plt.xlabel(&#39;epoch&#39;)</span></span>
<span class="line"><span>        plt.ylabel(&#39;loss&#39;)</span></span>
<span class="line"><span>        plt.show()</span></span></code></pre></div></div></div></main><footer class="VPDocFooter" data-v-ddd4901f data-v-d088cbcb><!--[--><!--]--><!----><!----></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"index.md\":\"B5zZUm5e\",\"linux_ffmpeg.md\":\"FzfWtUVK\",\"linux_git_git-add.md\":\"CPj3v1KF\",\"linux_git_git-bash介绍.md\":\"Bzq7PvYb\",\"linux_git_git-branch分支管理.md\":\"BDQPTwCw\",\"linux_git_git-clone.md\":\"Do9zHSd3\",\"linux_git_git-commit.md\":\"Dadu13Ou\",\"linux_git_git-push.md\":\"DmlZ-ADI\",\"linux_git_git-remote_管理远程仓库.md\":\"DZzf_QBV\",\"linux_git_git常用命令汇总.md\":\"D0UWEhSY\",\"linux_git_git的原理和.git文件夹.md\":\"cKWqWnIK\",\"linux_git_index.md\":\"zCFPICDo\",\"linux_git_个人项目最常用的四个命令.md\":\"C9ZwpfYd\",\"linux_git_安装git.md\":\"75Z2ov_T\",\"linux_git_最佳实践——使用git-clone而不是git-init.md\":\"DcmDpy2l\",\"linux_git_查看提交历史.md\":\"BUToX9Gp\",\"linux_git_标签.md\":\"CPVtIcyD\",\"linux_git_版本回退.md\":\"BB2bprDN\",\"linux_git_配置用户名、邮箱和ssh秘钥.md\":\"C2shR9Pw\",\"linux_index.md\":\"BLHgTLhR\",\"linux_linux与内核_linux的进程和服务.md\":\"CgcyXAD9\",\"linux_linux与内核_分区管理.md\":\"B-d-boFm\",\"linux_shell_awk工具.md\":\"DI9MPl-Q\",\"linux_shell_bash-shell.md\":\"BAwG1KEh\",\"linux_shell_powershell.md\":\"DE9ve-LS\",\"linux_shell_sed工具.md\":\"BchXtfTS\",\"linux_shell_vim.md\":\"C9t0HI4M\",\"linux_shell_命令行语法规则.md\":\"CKa4oI0F\",\"linux_shell_常用命令.md\":\"d1RtVUnL\",\"linux_shell_文件权限.md\":\"DgfXtjAi\",\"linux_shell_文件系统管理.md\":\"DlB7-tGy\",\"linux_shell_管道和多命令组合.md\":\"BIZy1uC3\",\"linux_shell_编写脚本.md\":\"BJQ2htb_\",\"linux_virtualbox.md\":\"Ccyc3hHm\",\"linux_云计算_docker.md\":\"BR4nlvBr\",\"linux_云计算_函数计算.md\":\"DdHSvtdb\",\"linux_基础.md\":\"FrhlGG5A\",\"linux_常用语言入门_c__入门.md\":\"DiGClf8U\",\"linux_常用语言入门_c语言入门.md\":\"gH3sdo5o\",\"linux_常用语言入门_java入门.md\":\"B3afQF9e\",\"linux_网络协议_tcp-ip.md\":\"-BwLIwlG\",\"temp notes_office.md\":\"C5MITBlC\",\"人工智能_index.md\":\"Dg2YDT4Z\",\"人工智能_python_http和web.md\":\"BSB62P5H\",\"人工智能_python_index.md\":\"Br81O27V\",\"人工智能_python_jupyter.md\":\"CTkLuxIV\",\"人工智能_python_numpy.md\":\"DT7cvYLl\",\"人工智能_python_pandas.md\":\"DSfSS-aW\",\"人工智能_python_元组和映射.md\":\"DUj3K9G4\",\"人工智能_python_函数.md\":\"D98ZXQYr\",\"人工智能_python_列表.md\":\"ClljJYno\",\"人工智能_python_基础和语法.md\":\"N1ipSJZg\",\"人工智能_python_字典.md\":\"BKW-CCuz\",\"人工智能_python_字符串.md\":\"Ck3pcJd1\",\"人工智能_python_序列.md\":\"Bs8QPfFF\",\"人工智能_python_异步.md\":\"B-sTgisM\",\"人工智能_python_时间模块.md\":\"C-MLWOhD\",\"人工智能_python_模块和包管理.md\":\"CqWWwqU9\",\"人工智能_python_正则表达式.md\":\"w19OQgzn\",\"人工智能_python_系统控制.md\":\"DpHXd3CZ\",\"人工智能_python_读写文件系统.md\":\"BI257SWK\",\"人工智能_python_面向对象.md\":\"rzA_Grxy\",\"人工智能_sd_comfyui.md\":\"BjaYF3xK\",\"人工智能_sd_stable-diffusion.md\":\"COxso8et\",\"人工智能_大模型_gradio.md\":\"CXyzodCI\",\"人工智能_大模型_transformer.md\":\"DrwJnyzv\",\"人工智能_大模型_大模型.md\":\"CDPSnyYa\",\"前端_css_index.md\":\"D8HNU9Lf\",\"前端_css_tailwindcss——响应式设计.md\":\"DvOzfCgM\",\"前端_css_tailwindcss——圆角.md\":\"DvhlnkIR\",\"前端_css_tailwindcss——媒体查询.md\":\"B2ZVHmxx\",\"前端_css_tailwindcss——宽度和高度.md\":\"Bq1HJ_nF\",\"前端_css_tailwindcss——布局.md\":\"H6aUzPb6\",\"前端_css_tailwindcss——弹性布局.md\":\"BXnX70_O\",\"前端_css_tailwindcss——文本.md\":\"2PI3NfDG\",\"前端_css_tailwindcss——背景.md\":\"C2AAXRIs\",\"前端_css_媒体查询.md\":\"CojOgsZU\",\"前端_css_定位.md\":\"D4_7tKy_\",\"前端_css_容器查询.md\":\"0jDsIROh\",\"前端_css_常见的颜色名称参考.md\":\"CRVPZ1rF\",\"前端_css_文字样式.md\":\"CmZc-4O9\",\"前端_css_样式优先级.md\":\"BURYwMc_\",\"前端_css_浮动.md\":\"C7w2rSPK\",\"前端_css_特效.md\":\"P0pqKlYY\",\"前端_css_背景、边框、轮廓.md\":\"BorGPuUP\",\"前端_css_选择器.md\":\"BpX9GrUO\",\"前端_css_锚点定位.md\":\"DhcL8DeP\",\"前端_electron_index.md\":\"DQERyuYT\",\"前端_html_a元素.md\":\"D09cUJQE\",\"前端_html_input元素.md\":\"Dt6-0VfK\",\"前端_html_input元素与表单提交.md\":\"D6cMJLVk\",\"前端_html_select表单元素.md\":\"DrL2Nfh3\",\"前端_html_video元素.md\":\"Bx_A_MBS\",\"前端_html_段落元素：p.md\":\"Dx7BgoB0\",\"前端_html_节点的属性.md\":\"CVWgROJ0\",\"前端_html_表单.md\":\"Bx3_KAHS\",\"前端_html_表格.md\":\"CjZr2XVK\",\"前端_html_音频.md\":\"hL6P4v6f\",\"前端_html_预格式文本元素pre和代码块元素code.md\":\"CRWsINLW\",\"前端_javascript_index.md\":\"DCaH1esg\",\"前端_javascript_代理.md\":\"Biw7lNFH\",\"前端_javascript_函数.md\":\"l4rz7JLu\",\"前端_javascript_原型和原型链.md\":\"C8PcoUCY\",\"前端_javascript_基础和语法.md\":\"sDjTSVq6\",\"前端_javascript_字符串.md\":\"BfnNRK7W\",\"前端_javascript_对象.md\":\"CO4zr1p1\",\"前端_javascript_数组.md\":\"bJKraIuh\",\"前端_javascript_期约和异步.md\":\"BJg7a2N9\",\"前端_javascript_正则表达式.md\":\"DMnXAs0I\",\"前端_javascript_迭代器和生成器.md\":\"CMxIAgUz\",\"前端_javascript_集合和映射.md\":\"C7Yfim_y\",\"前端_javascript_面向对象.md\":\"B-v0IqrG\",\"前端_node.js_00node.js——index.md\":\"B1L7jYBu\",\"前端_node.js_node.js——http.md\":\"DWDExFgE\",\"前端_node.js_node.js——http——axios.md\":\"BCradsvT\",\"前端_node.js_node.js——http——http协议简介.md\":\"BfFEwkrx\",\"前端_node.js_node.js——http——koa.js.md\":\"BQRS_vA2\",\"前端_node.js_node.js——http——node.js的http模块.md\":\"B8c2miFj\",\"前端_node.js_node.js——http——url()内置函数.md\":\"vT0NjnNS\",\"前端_node.js_node.js——http——一个简单的静态文件服务器.md\":\"Dawe9vvJ\",\"前端_node.js_node.js——http——典型的http客户端示例.md\":\"SWppPsnw\",\"前端_node.js_node.js——http——典型的http服务端示例.md\":\"CeArx0Ph\",\"前端_node.js_node.js——http——简单的服务器-客户端示例.md\":\"1K3GXWZy\",\"前端_node.js_node.js——http——简单的表单提交与接收示例.md\":\"CtFfx9Tp\",\"前端_node.js_node.js——http——请求报文和响应报文.md\":\"Dx6h0UBd\",\"前端_node.js_node.js——socket——socket服务端和客户端.md\":\"CSWPdD2t\",\"前端_node.js_node.js——socket——websocket.md\":\"BI0BYinO\",\"前端_node.js_node.js——zx.js——使用.md\":\"B2GUc-49\",\"前端_node.js_node.js——zx.js——内置函数.md\":\"D8TuJzNA\",\"前端_node.js_node.js——zx.js——简介.md\":\"u_FV-IuZ\",\"前端_node.js_node.js——事件.md\":\"BRy7ar0n\",\"前端_node.js_node.js——使用chilid_process模块开启多进程.md\":\"BjyhH9S4\",\"前端_node.js_node.js——使用net模块实现简单的多人聊天室.md\":\"QWNS6NFY\",\"前端_node.js_node.js——使用node.js实现一个简单的静态文件服务器.md\":\"MCjYM_PJ\",\"前端_node.js_node.js——多进程通信.md\":\"C8F49BSp\",\"前端_node.js_node.js——文件系统——node.js——文件系统——使用fs模块读写文件和目录.md\":\"Cpa7GIYS\",\"前端_node.js_node.js——模块——commanjs模块语法.md\":\"Bm0aKsXY\",\"前端_node.js_node.js——模块——es6模块语法.md\":\"BbS7_mhC\",\"前端_node.js_node.js——模块——npm的使用.md\":\"Bn65MvDY\",\"前端_node.js_node.js——模块——使用import和require.md\":\"vmSDlv6v\",\"前端_node.js_node.js——模块——模块查找规则.md\":\"B-PwCm3D\",\"前端_node.js_node.js——模块——注意：应该使用明确的相对路径.md\":\"BNnrDsuS\",\"前端_node.js_node.js——流.md\":\"CAHuoFRz\",\"前端_node.js_node.js——系统管理——使用path模块处理路径.md\":\"CkaVucKo\",\"前端_node.js_node.js——系统管理——调用系统命令.md\":\"BsSA3_KW\",\"前端_node.js_node.js——读取用户输入.md\":\"DqDkLJH4\",\"前端_react-native_adb命令的使用.md\":\"OBMZdPtQ\",\"前端_react-native_android——activity节点.md\":\"B6R9Q7YF\",\"前端_react-native_android——android项目源码结构.md\":\"Cymp4Gvt\",\"前端_react-native_android——manifest节点和application节点.md\":\"CDRYPvTM\",\"前端_react-native_android——user-permission节点.md\":\"CbQOILQ8\",\"前端_react-native_android——xml文件中的变量.md\":\"BQhBIuUL\",\"前端_react-native_android——签名.md\":\"C8UU5nyl\",\"前端_react-native_gradle.md\":\"A05Lln9v\",\"前端_react-native_index.md\":\"DHa8eFYM\",\"前端_react-native_jdk的安装和配置.md\":\"B2QxstlU\",\"前端_react-native_使用gradle打包安卓apk.md\":\"OaMenGxW\",\"前端_react-native_无线调试.md\":\"Clv8AaRR\",\"前端_react-native_有线调试.md\":\"DirBZpEx\",\"前端_react_index.md\":\"CcRdL73c\",\"前端_react_react——useeffect().md\":\"BE9XoxY3\",\"前端_react_react——usestate().md\":\"2Wq8-FGv\",\"前端_react_react——任意组件redux通信.md\":\"DMrRqQic\",\"前端_react_react——修改样式.md\":\"D69c42gx\",\"前端_react_react——在浏览器中使用.md\":\"d8OwZMvK\",\"前端_react_react——新建react项目.md\":\"DVC7elcg\",\"前端_react_react——服务端渲染框架：next.js.md\":\"BOw27Quk\",\"前端_react_react——父子组件props传值.md\":\"Cn0R8Pkj\",\"前端_react_react——组件.md\":\"yZj-kH_H\",\"前端_react_react——组件的生命周期.md\":\"D99ZgY7l\",\"前端_react_react——表单双向绑定.md\":\"CC-OAbKk\",\"前端_webrtc_index.md\":\"DurRa6rR\",\"前端_浏览器中的javascript_cookie.md\":\"BizT8Q7E\",\"前端_浏览器中的javascript_document对象.md\":\"DPkKfgSk\",\"前端_浏览器中的javascript_dom.md\":\"Cf6S_6pY\",\"前端_浏览器中的javascript_htmlelement类型.md\":\"TCixBwah\",\"前端_浏览器中的javascript_local storage.md\":\"FY3drh_L\",\"前端_浏览器中的javascript_requestanimationframe.md\":\"DEJwNwul\",\"前端_浏览器中的javascript_socket和websocket.md\":\"Cjhnqic4\",\"前端_浏览器中的javascript_web-api.md\":\"DuSD0PAY\",\"前端_浏览器中的javascript_元素的属性.md\":\"BKvg55Qz\",\"前端_浏览器中的javascript_理解dom.md\":\"cnHGY8BC\",\"前端_浏览器中的javascript_自定义事件.md\":\"Cvdfg68I\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"我的个人博客网站\",\"description\":\"个人博客网站\",\"base\":\"/blog/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>