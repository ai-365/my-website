<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>大模型 | VitePress</title>
    <meta name="description" content="A VitePress site">
    <meta name="generator" content="VitePress v1.6.3">
    <link rel="preload stylesheet" href="/assets/style.DhLflMQV.css" as="style">
    <link rel="preload stylesheet" href="/vp-icons.css" as="style">
    
    <script type="module" src="/assets/app.s7Ib0iH_.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.BFjbvQl1.js">
    <link rel="modulepreload" href="/assets/chunks/framework.BHrE6nLq.js">
    <link rel="modulepreload" href="/assets/AI_index.md.5X2inuI_.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-225761d0><!--[--><!--]--><!--[--><span tabindex="-1" data-v-14f1736c></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-14f1736c>Skip to content</a><!--]--><!----><header class="VPNav" data-v-225761d0 data-v-5d64fb7f><div class="VPNavBar" data-v-5d64fb7f data-v-c8f4d6d9><div class="wrapper" data-v-c8f4d6d9><div class="container" data-v-c8f4d6d9><div class="title" data-v-c8f4d6d9><div class="VPNavBarTitle" data-v-c8f4d6d9 data-v-acfe359a><a class="title" href="/" data-v-acfe359a><!--[--><!--]--><!----><span data-v-acfe359a>VitePress</span><!--[--><!--]--></a></div></div><div class="content" data-v-c8f4d6d9><div class="content-body" data-v-c8f4d6d9><!--[--><!--]--><div class="VPNavBarSearch search" data-v-c8f4d6d9><!----></div><!----><!----><div class="VPNavBarAppearance appearance" data-v-c8f4d6d9 data-v-f1f05694><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-f1f05694 data-v-0cacb664 data-v-dbbbfef5><span class="check" data-v-dbbbfef5><span class="icon" data-v-dbbbfef5><!--[--><span class="vpi-sun sun" data-v-0cacb664></span><span class="vpi-moon moon" data-v-0cacb664></span><!--]--></span></span></button></div><!----><div class="VPFlyout VPNavBarExtra extra" data-v-c8f4d6d9 data-v-d9e20dcd data-v-26e43672><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-26e43672><span class="vpi-more-horizontal icon" data-v-26e43672></span></button><div class="menu" data-v-26e43672><div class="VPMenu" data-v-26e43672 data-v-7aee09df><!----><!--[--><!--[--><!----><div class="group" data-v-d9e20dcd><div class="item appearance" data-v-d9e20dcd><p class="label" data-v-d9e20dcd>Appearance</p><div class="appearance-action" data-v-d9e20dcd><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-d9e20dcd data-v-0cacb664 data-v-dbbbfef5><span class="check" data-v-dbbbfef5><span class="icon" data-v-dbbbfef5><!--[--><span class="vpi-sun sun" data-v-0cacb664></span><span class="vpi-moon moon" data-v-0cacb664></span><!--]--></span></span></button></div></div></div><!----><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-c8f4d6d9 data-v-78339734><span class="container" data-v-78339734><span class="top" data-v-78339734></span><span class="middle" data-v-78339734></span><span class="bottom" data-v-78339734></span></span></button></div></div></div></div><div class="divider" data-v-c8f4d6d9><div class="divider-line" data-v-c8f4d6d9></div></div></div><!----></header><div class="VPLocalNav empty fixed" data-v-225761d0 data-v-546ba7ec><div class="container" data-v-546ba7ec><!----><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-546ba7ec data-v-4edf2666><button data-v-4edf2666>Return to top</button><!----></div></div></div><!----><div class="VPContent" id="VPContent" data-v-225761d0 data-v-9ab9c4bf><div class="VPDoc has-aside" data-v-9ab9c4bf data-v-fa71b28f><!--[--><!--]--><div class="container" data-v-fa71b28f><div class="aside" data-v-fa71b28f><div class="aside-curtain" data-v-fa71b28f></div><div class="aside-container" data-v-fa71b28f><div class="aside-content" data-v-fa71b28f><div class="VPDocAside" data-v-fa71b28f data-v-33f36bdb><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-33f36bdb data-v-3d352035><div class="content" data-v-3d352035><div class="outline-marker" data-v-3d352035></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-3d352035>On this page</div><ul class="VPDocOutlineItem root" data-v-3d352035 data-v-c1c7092a><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-33f36bdb></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-fa71b28f><div class="content-container" data-v-fa71b28f><!--[--><!--]--><main class="main" data-v-fa71b28f><div style="position:relative;" class="vp-doc _AI_" data-v-fa71b28f><div><h1 id="大模型" tabindex="-1">大模型 <a class="header-anchor" href="#大模型" aria-label="Permalink to &quot;大模型&quot;">​</a></h1><h2 id="大模型相关论文pdf汇总" tabindex="-1">大模型相关论文PDF汇总 <a class="header-anchor" href="#大模型相关论文pdf汇总" aria-label="Permalink to &quot;大模型相关论文PDF汇总&quot;">​</a></h2><h3 id="大名鼎鼎的transformer" tabindex="-1">大名鼎鼎的Transformer <a class="header-anchor" href="#大名鼎鼎的transformer" aria-label="Permalink to &quot;大名鼎鼎的Transformer&quot;">​</a></h3><ul><li>标题： Attention Is All You Need</li><li>中文标题： 注意力是你所需要的一切</li><li>发表时间： 2017年</li></ul><h3 id="cv领域的新基石-vision-transformer" tabindex="-1">CV领域的新基石： Vision Transformer <a class="header-anchor" href="#cv领域的新基石-vision-transformer" aria-label="Permalink to &quot;CV领域的新基石： Vision Transformer&quot;">​</a></h3><ul><li>标题： An Image Is Worth 16X16 Words： Transformers for Image Recognition At Scale</li><li>中文标题： 一张图片等价于16x16大小的字：将Transformer用于图像识别</li><li>发表时间： 2020年10月</li><li>论文地址： <a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noreferrer">https://arxiv.org/abs/2010.11929</a></li></ul><h3 id="文生图、文生视频的基石-diffusion-transformer" tabindex="-1">文生图、文生视频的基石：Diffusion Transformer <a class="header-anchor" href="#文生图、文生视频的基石-diffusion-transformer" aria-label="Permalink to &quot;文生图、文生视频的基石：Diffusion Transformer&quot;">​</a></h3><ul><li>标题： Scalsble Diffusion Models with Transformers （DiT）</li><li>中文标题： 基于Transformers的可扩展的扩散模型</li><li>发表时间： 2022年12月</li><li>地址： <a href="https://arxiv.org/pdf/2212.09748" target="_blank" rel="noreferrer">https://arxiv.org/pdf/2212.09748</a></li></ul><h3 id="分割一切大模型" tabindex="-1">分割一切大模型 <a class="header-anchor" href="#分割一切大模型" aria-label="Permalink to &quot;分割一切大模型&quot;">​</a></h3><ul><li>标题： Segment Anything</li><li>中文标题： 分割一切</li></ul><h3 id="开源文生视频-stable-video-diffusion" tabindex="-1">开源文生视频： Stable Video Diffusion <a class="header-anchor" href="#开源文生视频-stable-video-diffusion" aria-label="Permalink to &quot;开源文生视频： Stable Video Diffusion&quot;">​</a></h3><ul><li>发布时间： 2023年11月</li></ul><h3 id="什么是微调" tabindex="-1">什么是微调？ <a class="header-anchor" href="#什么是微调" aria-label="Permalink to &quot;什么是微调？&quot;">​</a></h3><p>从头开始训练模型，成本高昂。 对所有的参数进行微调，是低效的。 固定前面的层，只微调接近下游的那几层参数，效果又不好。 将高维映射到低维，然后经过一个线性层，再从低维还原到高维。</p><h3 id="什么是强化学习" tabindex="-1">什么是强化学习？ <a class="header-anchor" href="#什么是强化学习" aria-label="Permalink to &quot;什么是强化学习？&quot;">​</a></h3><p>通过与环境交互，根据反馈来学习最佳行为。 智能体评估当前的状态，采取相应的动作，根据动作的正确与否得到奖励或惩罚。 智能体通过与环境的互动，学习到一个策略，使奖励最大化。</p><h3 id="google-io-2024发布内容简介" tabindex="-1">Google IO 2024发布内容简介 <a class="header-anchor" href="#google-io-2024发布内容简介" aria-label="Permalink to &quot;Google IO 2024发布内容简介&quot;">​</a></h3><p>基本围绕AI。Veo视频生成模型。Gemini 大模型。 Agent工具。AI辅助编程工具等。</p><h2 id="大模型文件后缀名及其含义" tabindex="-1">大模型文件后缀名及其含义 <a class="header-anchor" href="#大模型文件后缀名及其含义" aria-label="Permalink to &quot;大模型文件后缀名及其含义&quot;">​</a></h2><p>（1） safetensors</p><p>这是由 Hugging Face 推出的一种新型安全模型存储格式，特别关注模型安全性、隐私保护和快速加载。它仅包含模型的权重参数，而不包括执行代码，这样可以减少模型文件大小，提高加载速度。</p><p>（2） ckpt</p><p>PyTorch Lightning 框架采用的模型存储格式。它不仅包含了模型参数，还包括优化器状态以及可能的训练元数据信息，使得用户可以无缝地恢复训练或执行推理。</p><p>（3） bin</p><p>通常是一种通用的二进制格式文件，它可以用来存储任意类型的数据。但在某些情况下可用于存储原始二进制权重数据，加载时需额外处理。</p><p>（4） pth</p><p>是 PyTorch 中用于保存模型状态的标准格式。方便模型的持久化和复用，支持完整模型结构和参数的保存与恢复。</p><h2 id="huggingface" tabindex="-1">Huggingface <a class="header-anchor" href="#huggingface" aria-label="Permalink to &quot;Huggingface&quot;">​</a></h2><h3 id="hugging-face镜像站" tabindex="-1">Hugging Face镜像站 <a class="header-anchor" href="#hugging-face镜像站" aria-label="Permalink to &quot;Hugging Face镜像站&quot;">​</a></h3><p>国内网络环境无法使用Huggingface，可以使用其镜像站 ：<a href="https://hf-mirror.com" target="_blank" rel="noreferrer">https://hf-mirror.com</a></p><p>要下载镜像站的大模型文件，有两种方式。</p><p>方法一： 直接在网页下载</p><p>打开大模型页面 <a href="https://hf-mirror.com/%E7%94%A8%E6%88%B7%E5%90%8D/%E6%A8%A1%E5%9E%8B%E5%90%8D" target="_blank" rel="noreferrer">https://hf-mirror.com/用户名/模型名</a> ，进入files标签，直接下载里面的文件。</p><p>方法二： 使用命令行工具</p><p>首先安装命令行工具Python包：</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">pip</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  install</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  -U</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  huggingface_hub</span></span></code></pre></div><p>然后设置环境变量 HF_ENDPOINT = &quot;<a href="https://hf-mirror.com" target="_blank" rel="noreferrer">https://hf-mirror.com</a>&quot;</p><p>然后下载模型：</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">huggingface-cli</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  download</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --resume-download</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  gpt2</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --local-dir</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  gpt2</span></span></code></pre></div><p>下载数据集：</p><div class="language-sh vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">huggingface-cli</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  download</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --repo-type</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  drataset</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --esume-download</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  wikitext</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  --local-dir</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">  wikitext</span></span></code></pre></div><p>注意，有些项目需要登录Huggingface Face源站获取Token才能下载。</p><h3 id="指定本地路径-避免反复下载" tabindex="-1">指定本地路径，避免反复下载 <a class="header-anchor" href="#指定本地路径-避免反复下载" aria-label="Permalink to &quot;指定本地路径，避免反复下载&quot;">​</a></h3><p>大模型文件很大，每次都重新下载费时费力，因此可以指定本地路径。from_pretrain 函数可以接收一个模型的id，也可以接收模型的本地存储路径。</p><p>先在网络较好时将HF上的整个文件夹下载下来，然后推理的时候指定本地的这个文件夹即可。</p><h2 id="强化学习" tabindex="-1">强化学习 <a class="header-anchor" href="#强化学习" aria-label="Permalink to &quot;强化学习&quot;">​</a></h2><ul><li>提示学习</li></ul><p>插槽式、类似于插值字符串</p><ul><li>语境学习</li></ul><p>带有情感极性的句子示例</p><ul><li>高效模型微调LoRA</li></ul><p>在原本矩阵旁边添加低秩矩阵 在残差连接添加适配层作为可训练参数</p><ul><li>低秩矩阵</li></ul><p>秩序：矩阵中最大不相关向量的个数，可以理解为有秩序的程度。</p><p>矩阵的秩的度量其实就是矩阵的行列之间的相关性。如果矩阵的各行或列是线性无关的，矩阵就是满秩的。非零元素的行数或列数决定了秩的多少。</p><p>低秩矩阵：矩阵的秩相对矩阵的行数或列数而言很小。</p><p>图像处理中，秩可以理解为包含信息的丰富程度。如果一张草原图全是草，那么就是低秩。</p><ul><li>稀疏矩阵</li></ul><p>稀疏是指矩阵中非零元素的个数少。</p><ul><li>思维链</li></ul><p>解题思路和步骤输入给模型，使得模型不仅有结果，还有中间步骤。</p><h2 id="深度学习" tabindex="-1">深度学习 <a class="header-anchor" href="#深度学习" aria-label="Permalink to &quot;深度学习&quot;">​</a></h2><h2 id="深度学习的基本概念" tabindex="-1">深度学习的基本概念 <a class="header-anchor" href="#深度学习的基本概念" aria-label="Permalink to &quot;深度学习的基本概念&quot;">​</a></h2><h3 id="残差连接" tabindex="-1">残差连接 <a class="header-anchor" href="#残差连接" aria-label="Permalink to &quot;残差连接&quot;">​</a></h3><p>将输入多次处理后，再和最开始的那个输入做一次加法运算</p><h3 id="归一化" tabindex="-1">归一化 <a class="header-anchor" href="#归一化" aria-label="Permalink to &quot;归一化&quot;">​</a></h3><p>使一组数据限定在一个范围内，如0~1或-1~1，以加快收敛</p><h3 id="线性层" tabindex="-1">线性层 <a class="header-anchor" href="#线性层" aria-label="Permalink to &quot;线性层&quot;">​</a></h3><p>加入一组权重，然后不断训练调整</p><h3 id="softmax" tabindex="-1">SoftMax <a class="header-anchor" href="#softmax" aria-label="Permalink to &quot;SoftMax&quot;">​</a></h3><p>将一组值转为一组概率，总和为1</p><h3 id="激活函数" tabindex="-1">激活函数 <a class="header-anchor" href="#激活函数" aria-label="Permalink to &quot;激活函数&quot;">​</a></h3><p>增加非线性，如果没有激活函数，就算层再多跟一层也没区别。目前最常用的是ReLu。</p><h3 id="epoch" tabindex="-1">epoch <a class="header-anchor" href="#epoch" aria-label="Permalink to &quot;epoch&quot;">​</a></h3><p>把整个数据集遍历一次称为一个epoch。推荐每运行完一个epoch就保存一次记录，这样就有更多的模型可供选择。</p><h3 id="repeat" tabindex="-1">repeat <a class="header-anchor" href="#repeat" aria-label="Permalink to &quot;repeat&quot;">​</a></h3><p>单张图片的重复遍历次数。在当前的epoch中，每张图片被遍历的次数。</p><h3 id="batch-size" tabindex="-1">batch-size <a class="header-anchor" href="#batch-size" aria-label="Permalink to &quot;batch-size&quot;">​</a></h3><p>批次大小。较大的批次训练速度更快，但需要更大的显存，需要更多的批次才能收敛。较小的batch size训练较慢，但显存占用更小，模型收敛的更快。</p><h3 id="过拟合和欠拟合的最通俗解释" tabindex="-1">过拟合和欠拟合的最通俗解释 <a class="header-anchor" href="#过拟合和欠拟合的最通俗解释" aria-label="Permalink to &quot;过拟合和欠拟合的最通俗解释&quot;">​</a></h3><p>欠拟合：没学会。 过拟合：学会了，但是学痴了，但能举一反三。</p><h2 id="pytorch" tabindex="-1">PyTorch <a class="header-anchor" href="#pytorch" aria-label="Permalink to &quot;PyTorch&quot;">​</a></h2><h3 id="pytorch相对numpy的优势" tabindex="-1">PyTorch相对Numpy的优势 <a class="header-anchor" href="#pytorch相对numpy的优势" aria-label="Permalink to &quot;PyTorch相对Numpy的优势&quot;">​</a></h3><p>PyTorch和Numpy的数组可以互相转换，本质上并无区别。PyTorch相对于Numpy的优势在于：</p><ul><li>支持GPU并行加速</li><li>自动微分</li></ul><p>所以，PyTorch 比 Numpy 快，而 Numpy 又比 Python 原生数组快！</p><h3 id="将张量放入gpu环境" tabindex="-1">将张量放入GPU环境 <a class="header-anchor" href="#将张量放入gpu环境" aria-label="Permalink to &quot;将张量放入GPU环境&quot;">​</a></h3><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>import torch </span></span>
<span class="line"><span>print(torch.__version__)# torch版本</span></span>
<span class="line"><span>print(torch.version.cuda) #cuda版本</span></span>
<span class="line"><span>print(torch.cuda.is_available()) #cuda是否可用</span></span></code></pre></div><table tabindex="0"><thead><tr><th>代码</th><th>注释</th></tr></thead><tbody><tr><td>device = torch.device(&quot;cuda&quot;)</td><td>使用GPU环境</td></tr><tr><td>device = torch.device(&quot;cpu&quot;)</td><td>使用CPU环境</td></tr><tr><td>A.device</td><td>判断对象在哪个环节</td></tr><tr><td>A= A.to(device)</td><td>放入device中</td></tr><tr><td>A.cpu().device</td><td>放入CPU中</td></tr></tbody></table><p>torch.tensor(1.0) #标量 torch.tensor([[1.0,1.0],[1.0,1.0]])#二维数组 (2,2)</p><h2 id="张量" tabindex="-1">张量 <a class="header-anchor" href="#张量" aria-label="Permalink to &quot;张量&quot;">​</a></h2><h3 id="张量简介" tabindex="-1">张量简介 <a class="header-anchor" href="#张量简介" aria-label="Permalink to &quot;张量简介&quot;">​</a></h3><p>张量是PyTorch等深度学习框架中最基本的数据结构。张量的本质是多维数组，可以是一维的向量、二维的矩阵、三维的数组。</p><h3 id="张量的元素类型" tabindex="-1">张量的元素类型 <a class="header-anchor" href="#张量的元素类型" aria-label="Permalink to &quot;张量的元素类型&quot;">​</a></h3><table tabindex="0"><thead><tr><th>类型</th><th>CPU表示</th><th>GPU表示</th></tr></thead><tbody><tr><td>32位短整型</td><td>torch.IntTensor</td><td>torch.cuda.intTensor</td></tr><tr><td>64位长整型</td><td>torch.LongTensor</td><td>torch.cuda.LongTensor</td></tr><tr><td>单精度浮点型</td><td>torch.FloatTensor</td><td>torch.cuda.FloatTensor</td></tr><tr><td>双精度浮点型</td><td>torch.DoubleTensor</td><td>torch.cuda.DoubleTensor</td></tr></tbody></table><h3 id="特殊的张量" tabindex="-1">特殊的张量 <a class="header-anchor" href="#特殊的张量" aria-label="Permalink to &quot;特殊的张量&quot;">​</a></h3><table tabindex="0"><thead><tr><th>代码</th><th>作用</th></tr></thead><tbody><tr><td>torch.zeros(m,n)</td><td>mxn的全0矩阵</td></tr><tr><td>torch.ones(m,n)</td><td>mxn的全1矩阵</td></tr><tr><td>torch.eye(m,n)</td><td>mxn的单位矩阵，对角线为1，其它为0</td></tr><tr><td>torch.randn(m,n)</td><td>mxn的正态分布的随机数，0~1之间</td></tr><tr><td>torch.rand(m,n)</td><td>mxn的均匀分布的随机数，0~1之间</td></tr><tr><td>torch.Tensor([4,5,5,6])</td><td>根据数组字面量直接创建张量</td></tr><tr><td>torch.IntTensor([1,2])</td><td>指定数据类型</td></tr></tbody></table><p>索引操作 y = x[0, : ] 第1行</p><h3 id="张量和numpy数组的互转" tabindex="-1">张量和Numpy数组的互转 <a class="header-anchor" href="#张量和numpy数组的互转" aria-label="Permalink to &quot;张量和Numpy数组的互转&quot;">​</a></h3><p>Numpy转Tensor：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>arr = np.ones(5,3)</span></span>
<span class="line"><span>T  = torch.from_numpy(a)</span></span></code></pre></div><p>改变张量的形状</p><p>张量对象调用view()方法可以改变形状 ，例如：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>import torch </span></span>
<span class="line"><span>T1 = Torch.ones(3,8)</span></span>
<span class="line"><span>T2 = T1.view(4,6)</span></span></code></pre></div><p>也可以将某个维度的长度设置为-1，会自动计算：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>import torch </span></span>
<span class="line"><span>T1 = Torch.ones(3,8)</span></span>
<span class="line"><span>T2 = T1.view(-1 ,6)   # 第一维自动计算</span></span></code></pre></div><p>还有两个方法去掉或增加长度为1的维度：</p><ul><li>squeeze(T) ： 去掉长度为1的维度</li><li>unsqueeze(T) ： 增加长度为1的维度</li></ul><p>dataloader的参数</p><p>dataset 数据集 batch_size 批次大小，默认1</p><p>Epoch： 所有的样本都输入到模型中，称为一个epoch Iteration： 一个Batch的样本输入到模型中，称为一个Iteration batch_size： 一个批次的大小，一个Epoch=Batchsize*Iteration</p><p>DataLoader()的参数： dataset 数据集 batch_size 批次大小 shuffle 是否乱序 sampler 样本采样函数，一般无需设置 batch_sampler 批次采样函数，一般无需设置 num_workers 使用多进程读取数据，使用的进程数 collate_fn 整理一个批次数据的函数</p><p>Dataset 数据集 DataLoader 数据装载器</p><p>自建数据集： dataset = TensorDataset(torch.arange(1, 40)) dl = DataLoader(dataset, batch_size=10) # 批次大小10，因此有4个批次</p><h3 id="矩阵的乘法" tabindex="-1">矩阵的乘法 <a class="header-anchor" href="#矩阵的乘法" aria-label="Permalink to &quot;矩阵的乘法&quot;">​</a></h3><p>T1.matmul(T2) T1 @ T2 # 与上等价</p><p>神经网络和矩阵乘法的对应</p><p>神经网络和矩阵乘法的对应关系如下图所示：</p><pre><code>首先将输入展平为一个一维向量，中间的每条线对应着一个数值，这些数值组合起来就是一个矩阵，在深度学习中叫做权重。如果每个输入跟每个输出全部相连，就叫做全连接。
</code></pre><p>torch.nn torch.nn是神经网络工具箱，该工具箱建立于Autogard（主要有自动求导和梯度反向传播功能），提供了网络搭建的模组，优化器等一系列功能。</p><p>搭建一个神经网络的整体流程： 数组读取 定义模型 定义损失函数和优化器 模型训练 获取训练结果</p><p>Torch 运算 torch.item() 取出数据，注意，只有一个元素时才能用 T.numpy() 转为Numpy T.from_numpy() 从Numpy导入 T.view() 变形、重构尺寸，类 似Numpy的reshape变形 T.transpose(0,1) 行列交换</p><p>拼接stack torch.stack((A,B), dim=0) dim表示拼接方向</p><p>正向传播、反向传播</p><p>正向：由输入得到输出 反向：根据损失函数计算预测值与真实值之间的误差，计算每个节点对应的输入的梯度，最终得到参数的梯度信息。</p><p>梯度 为什么要算梯度？ 使得损失函数最小，梯度（斜率）为0 y.backward() 计算梯度 x.grad 获取梯度值</p><p>梯度下降法是一种致力于找到函数极值点的算法。所谓“训练”或“学习”就是改进模型参数，以便通过大量训练步骤将损失最小化。梯度下降法的思路很简单，就是沿着函数下降最快的方向改变模型参数，直到到达最低点。</p><p>超参数 超参数就是需要用户手工配置的参数。</p><p>学习率 Wi+1 = Wi - 学习率 x ▽Wi 学习率就是每次下降的幅度。太小，则需要很多轮迭代，浪费资源； 太大，则可能会跳过最小点</p><p>一个简单的神经网络示例</p><p>我们拿一个最简单的FNN网络来对经典数据集diabetes糖尿病数据集来进行分类预测。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>    import numpy as np	</span></span>
<span class="line"><span>    import torch</span></span>
<span class="line"><span>    import matplotlib.pyplot as plt</span></span>
<span class="line"><span>    from torch.utils.data import Dataset, DataLoader</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    # Prepare the dataset 准备数据集</span></span>
<span class="line"><span>    class DiabetesDateset(Dataset):</span></span>
<span class="line"><span>        # 加载数据集</span></span>
<span class="line"><span>        def __init__(self, filepath):</span></span>
<span class="line"><span>            xy = np.loadtxt(filepath, delimiter=&#39;,&#39;, dtype=np.float32, encoding=&#39;utf-8&#39;)</span></span>
<span class="line"><span>            self.len = xy.shape[0]  # shape[0]是矩阵的行数,shape[1]是矩阵的列数</span></span>
<span class="line"><span>            self.x_data = torch.from_numpy(xy[:, :-1])</span></span>
<span class="line"><span>            self.y_data = torch.from_numpy(xy[:, [-1]])</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>        # 获取数据索引</span></span>
<span class="line"><span>        def __getitem__(self, index):</span></span>
<span class="line"><span>            return self.x_data[index], self.y_data[index]</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>        # 获得数据总量</span></span>
<span class="line"><span>        def __len__(self):</span></span>
<span class="line"><span>            return self.len</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    dataset = DiabetesDateset(&#39;diabetes.csv&#39;)</span></span>
<span class="line"><span>    </span></span>
<span class="line"><span>    train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=2)  </span></span>
<span class="line"><span>    # num_workers为多线程</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    # Define the model   定义模型</span></span>
<span class="line"><span>    </span></span>
<span class="line"><span>    class FNNModel(torch.nn.Module):</span></span>
<span class="line"><span>        def __init__(self):</span></span>
<span class="line"><span>            super(FNNModel, self).__init__()</span></span>
<span class="line"><span>            self.linear1 = torch.nn.Linear(8, 6)  # 输入数据的特征有8个,也就是有8个维度,随后将其降维到6维</span></span>
<span class="line"><span>            self.linear2 = torch.nn.Linear(6, 4)  # 6维降到4维</span></span>
<span class="line"><span>            self.linear3 = torch.nn.Linear(4, 2)  # 4维降到2维</span></span>
<span class="line"><span>            self.linear4 = torch.nn.Linear(2, 1)  # 2w维降到1维</span></span>
<span class="line"><span>            self.sigmoid = torch.nn.Sigmoid()  # 可以视其为网络的一层,而不是简单的函数使用</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>        def forward(self, x):</span></span>
<span class="line"><span>            x = self.sigmoid(self.linear1(x))</span></span>
<span class="line"><span>            x = self.sigmoid(self.linear2(x))</span></span>
<span class="line"><span>            x = self.sigmoid(self.linear3(x))</span></span>
<span class="line"><span>            x = self.sigmoid(self.linear4(x))</span></span>
<span class="line"><span>            return x</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    model = FNNModel()</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    # Define the criterion and optimizer 定义优化和损失</span></span>
<span class="line"><span>    criterion = torch.nn.BCELoss(reduction=&#39;mean&#39;)  # 返回损失的平均值</span></span>
<span class="line"><span>    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    epoch_list = []</span></span>
<span class="line"><span>    loss_list = []</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>    # Training  训练</span></span>
<span class="line"><span>    if __name__ == &#39;__main__&#39;: </span></span>
<span class="line"><span>        for epoch in range(100):</span></span>
<span class="line"><span>            # i是一个epoch中第几次迭代,一共756条数据,每个mini_batch为32,所以一个epoch需要迭代23次</span></span>
<span class="line"><span>            # data获取的数据为(x,y)</span></span>
<span class="line"><span>            loss_one_epoch = 0</span></span>
<span class="line"><span>            for i, data in enumerate(train_loader, 0):</span></span>
<span class="line"><span>                inputs, labels = data    # 输入实际</span></span>
<span class="line"><span>                y_pred = model(inputs)  #  预测输入</span></span>
<span class="line"><span>                loss = criterion(y_pred, labels)  # 预测实际</span></span>
<span class="line"><span>                loss_one_epoch += loss.item()</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>                optimizer.zero_grad()</span></span>
<span class="line"><span>                loss.backward()</span></span>
<span class="line"><span>                optimizer.step()</span></span>
<span class="line"><span>            loss_list.append(loss_one_epoch / 23)</span></span>
<span class="line"><span>            epoch_list.append(epoch)</span></span>
<span class="line"><span>            print(&#39;Epoch[{}/{}],loss:{:.6f}&#39;.format(epoch + 1, 100, loss_one_epoch / 23))</span></span>
<span class="line"><span>     </span></span>
<span class="line"><span>        # Drawing</span></span>
<span class="line"><span>        plt.plot(epoch_list, loss_list)</span></span>
<span class="line"><span>        plt.xlabel(&#39;epoch&#39;)</span></span>
<span class="line"><span>        plt.ylabel(&#39;loss&#39;)</span></span>
<span class="line"><span>        plt.show()</span></span></code></pre></div><h1 id="gradio" tabindex="-1">Gradio <a class="header-anchor" href="#gradio" aria-label="Permalink to &quot;Gradio&quot;">​</a></h1><h2 id="安装gradio" tabindex="-1">安装gradio <a class="header-anchor" href="#安装gradio" aria-label="Permalink to &quot;安装gradio&quot;">​</a></h2><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>pip install gradio</span></span></code></pre></div><h2 id="导入gradio" tabindex="-1">导入gradio <a class="header-anchor" href="#导入gradio" aria-label="Permalink to &quot;导入gradio&quot;">​</a></h2><div class="language-py vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">py</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> gradio </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> gr</span></span></code></pre></div><h2 id="一个简单的示例" tabindex="-1">一个简单的示例 <a class="header-anchor" href="#一个简单的示例" aria-label="Permalink to &quot;一个简单的示例&quot;">​</a></h2><div class="language-py vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">py</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> gradio </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> gr</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> greet</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(name, intensity):  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 参数列表对应输入 name文本框、intensity滑块</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;Hello, &quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> +</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> name </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;!&quot;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(intensity)   </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 输出对应，文本框</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">demo </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> gr.Interface(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    fn</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">greet ,   </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定函数</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    inputs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;slider&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] ,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定输入类型： 一个文本框、一个滑块</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    outputs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指定输出类型</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">demo.launch()</span></span></code></pre></div><h2 id="gr-interface-的三大重要参数" tabindex="-1">gr.Interface()的三大重要参数 <a class="header-anchor" href="#gr-interface-的三大重要参数" aria-label="Permalink to &quot;gr.Interface()的三大重要参数&quot;">​</a></h2><p>Gradio的核心是Interface类，它允许用户定义输入和输出类型，创建交互式的Web界面。gr.Interface()有三大重要参数：</p><ul><li>fn处理函数： 用于定义如何根据输入返回输出。</li><li>inputs输入列表： 输入可以有一个或多个（列表）。每个元素支持多种输入类型，如gr.Text()用于文本输入，gr.Image()用于图像上传，gr.Audio()用于音频输入等。</li><li>outputs输出列表：输出使用函数的return指定，可以输出一个或多个。</li></ul><h2 id="interface-的其它参数" tabindex="-1">Interface()的其它参数 <a class="header-anchor" href="#interface-的其它参数" aria-label="Permalink to &quot;Interface()的其它参数&quot;">​</a></h2><ul><li>title ：标题</li><li>description ：描述</li><li>layout： 输入输出组件的布局</li><li>theme 界面主题风格，如dark</li><li>css ： css样式</li><li>layout： 使用layout=&quot;grouped&quot;或layout=&quot;stacked&quot;来更改组件的排列方式，使界面更加紧凑或分散。</li></ul><h2 id="数据类型" tabindex="-1">数据类型 <a class="header-anchor" href="#数据类型" aria-label="Permalink to &quot;数据类型&quot;">​</a></h2><p>文本类：</p><table tabindex="0"><thead><tr><th>类型</th><th>简写</th><th>含义</th><th>参数列表</th></tr></thead><tbody><tr><td>gr.Text()</td><td>text</td><td>单行文本输入框</td><td></td></tr><tr><td>gr.Textbox()</td><td>textbox</td><td>单行文本输入框</td><td>default：默认文本;placeholder：占位符文本</td></tr><tr><td>gr.Textarea()</td><td>textarea</td><td>多行文本输入框</td><td>lines：显示行数，整数值;placeholder： 占位符文本</td></tr><tr><td>gr.Number()</td><td>number</td><td>数字输入框</td><td>default：默认数字;label：标签文本</td></tr><tr><td>gr.Time()</td><td>time</td><td>输入时间</td><td>label：标签文本</td></tr><tr><td>gr.Slider()</td><td>slider</td><td>滑动条，用于选择一定范围的数值</td><td>minimum： 最小值;maximum：最大;step：步长;label：标签文本</td></tr><tr><td>gr.Radio()</td><td>radio</td><td>单选框</td><td>choices：字符串数组;label： 标签文本</td></tr><tr><td>gr.Checkbox()</td><td>checkbox</td><td>复选框，布尔类型</td><td>label：复选框旁边的文本</td></tr><tr><td>gr.ColorPicker()</td><td>colorpicker</td><td>选择颜色，十六进制颜色代码</td><td>default：默认颜色值</td></tr><tr><td>gr.Dropdown()</td><td>dropdown</td><td>下拉菜单</td><td>choices：字符串数组</td></tr></tbody></table><p>附件类：</p><table tabindex="0"><thead><tr><th>类型</th><th>简写</th><th>含义</th><th>参数列表</th></tr></thead><tbody><tr><td>gr.File()</td><td>file</td><td>上传任意文件</td><td>file_count： 允许上传的数量，取值single（只能传一个）、multiple（可以传多个）; type： 数据类型，如file、audio</td></tr><tr><td>gr.Dataframe()</td><td>dataframe</td><td>上传csv文件或输入dataframe</td><td>headers: 列标题数组; row_count: 初始显示的行数</td></tr><tr><td>gr.Data()</td><td>data</td><td>上传二进制数据，用于上传音频或视频的原始字节</td><td>type：类型，可以是 auto 自动推断</td></tr><tr><td>gr.Image()</td><td>image</td><td>上传图片，支持多种图像格式</td><td>type： 图像类型，如pil</td></tr><tr><td>gr.Video()</td><td>video</td><td>上传视频</td><td>label：标签文本</td></tr><tr><td>gr.Audio()</td><td>audio</td><td>上传音频</td><td>source：指定音频来源;type：指定返回类型;label：标签文本</td></tr></tbody></table><h2 id="输出组件的类型" tabindex="-1">输出组件的类型 <a class="header-anchor" href="#输出组件的类型" aria-label="Permalink to &quot;输出组件的类型&quot;">​</a></h2><p>输出组件的类型除了包括上面表格中的类型以外，还包括：</p><ul><li>Carousel：以轮播方式展示多个输出，适用于图像集多个数据点。参数：item_type 设置轮播项目类型。例：gr.Carousel(item_type=&quot;image&quot;)</li><li>Gallery：以画廊形式展示一系列图像。</li><li>HTML：展示HTML内容，适用于富文本或网页布局。</li><li>Image：展示图像。参数：type 指定图像格式。 例：gr.Image(type=&quot;pil&quot;)</li><li>JSON：以JSON格式展示数据，便于查看结构化数据。</li><li>KeyValues：以键值对形式展示数据。</li><li>Label：展示文本标签，适用于简单的文本输出。</li><li>Markdown：支持Markdown格式的文本展示。</li><li>Plot：展示图表，如matplotlib生成的图表。</li><li>Text：用于显示文本，适合较长的输出。</li></ul><h2 id="gradio集成大模型" tabindex="-1">Gradio集成大模型 <a class="header-anchor" href="#gradio集成大模型" aria-label="Permalink to &quot;Gradio集成大模型&quot;">​</a></h2><p>如下代码集成了HuggingFace的图像分类模型：</p><div class="language-py vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">py</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> gradio </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> gr</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 加载Huggingface上的预训练模型</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pipeline(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;image-classification&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 定义处理函数</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> classify_image</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(img):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {i[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;label&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]: i[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;score&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model(img)}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建Gradio界面</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">iface </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> gr.Interface(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    fn</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">classify_image,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    inputs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gr.Image(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;pil&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),   </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">## 图片类型</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    outputs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gr.Label(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">num_top_classes</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">iface.launch()</span></span></code></pre></div><p><img src="/assets/Gradio.DrdRigXG.png" alt="Gradio"></p><h1 id="stable-diffusion" tabindex="-1">Stable Diffusion <a class="header-anchor" href="#stable-diffusion" aria-label="Permalink to &quot;Stable Diffusion&quot;">​</a></h1><h2 id="ai绘画的应用场景" tabindex="-1">AI绘画的应用场景 <a class="header-anchor" href="#ai绘画的应用场景" aria-label="Permalink to &quot;AI绘画的应用场景&quot;">​</a></h2><ul><li>人物 <ul><li>换脸</li><li>换装</li><li>换姿势</li><li>换表情</li></ul></li><li>抠图</li><li>局部重绘</li><li>放大</li><li>换背景</li><li>换颜色</li></ul><h2 id="stable-diffusion-1" tabindex="-1">Stable Diffusion <a class="header-anchor" href="#stable-diffusion-1" aria-label="Permalink to &quot;Stable Diffusion&quot;">​</a></h2><h3 id="sd的发布时间" tabindex="-1">SD的发布时间 <a class="header-anchor" href="#sd的发布时间" aria-label="Permalink to &quot;SD的发布时间&quot;">​</a></h3><p>1.0发布于2022年9月，2.0发布于2022年11月，3.0发布于2024年5月。</p><h3 id="sdxl简介" tabindex="-1">SDXL简介 <a class="header-anchor" href="#sdxl简介" aria-label="Permalink to &quot;SDXL简介&quot;">​</a></h3><p>SDXL 就是 SD 的升级版，图片生成的效果更好、更逼真、分辨率更高。</p><h3 id="sd的主要原理" tabindex="-1">SD的主要原理 <a class="header-anchor" href="#sd的主要原理" aria-label="Permalink to &quot;SD的主要原理&quot;">​</a></h3><p>将输入（文本或图片）向量化 ——&gt; 通过VAE压缩到Latent隐空间 ——&gt; 在隐空间中多次去噪 ——&gt; 通过VAE解码还原到像素空间</p><h3 id="从-u-net-到transformer" tabindex="-1">从 U-Net 到Transformer <a class="header-anchor" href="#从-u-net-到transformer" aria-label="Permalink to &quot;从 U-Net 到Transformer&quot;">​</a></h3><p>由于自注意力的可扩展性、强大的性能，扩散模型背后的骨干网络，已经由U-Net替换成了Transformer架构。Transformer 已然完成了深度学习领域的大一统。</p><h3 id="隐空间的作用" tabindex="-1">隐空间的作用 <a class="header-anchor" href="#隐空间的作用" aria-label="Permalink to &quot;隐空间的作用&quot;">​</a></h3><p>隐空间通俗来说将图片数据量压缩，这样便于提升训练和推理的性能。类似于视频帧的压缩。</p><h3 id="sd应用的主要文件夹" tabindex="-1">SD应用的主要文件夹 <a class="header-anchor" href="#sd应用的主要文件夹" aria-label="Permalink to &quot;SD应用的主要文件夹&quot;">​</a></h3><p>重点关注几个文件夹： checkpoint 大模型文件夹 、 embeddings 向量化、Lora微调、VAE变分自编码器、 ControlNet插件、Custom Nodes 自定义节点</p><h2 id="lora训练" tabindex="-1">LoRA训练 <a class="header-anchor" href="#lora训练" aria-label="Permalink to &quot;LoRA训练&quot;">​</a></h2><h3 id="repeat、epoch、batch-size的区别" tabindex="-1">repeat、epoch、batch_size的区别 <a class="header-anchor" href="#repeat、epoch、batch-size的区别" aria-label="Permalink to &quot;repeat、epoch、batch_size的区别&quot;">​</a></h3><p><img src="/assets/repeat%E3%80%81epoch%E3%80%81batch_size.D_nZOk6Y.png" alt="repeat、epoch、batch_size"></p><h3 id="学习率" tabindex="-1">学习率 <a class="header-anchor" href="#学习率" aria-label="Permalink to &quot;学习率&quot;">​</a></h3><p>学习率类似于车速。学习率过高，学的太快，囫囵吞枣，可能会过拟合。学习率太低，可以更好看清路上的风景，也就是AI可以更细致的去学习，但是可能会导致不拟合，也就是出图完全不像，学的太慢了，并且花费的时间更多。</p><p>学习率默认值1e-4，即0.0001。</p><h3 id="打tag" tabindex="-1">打tag <a class="header-anchor" href="#打tag" aria-label="Permalink to &quot;打tag&quot;">​</a></h3><p><strong>如果是希望灵活调整的特征，都必须把tag打清楚</strong>。如果是固化在模型里面的特征，都不要去打tag。例如，如果希望头发颜色可以自定义，则必须写明 red hair ，如果不写明，将来AI会认为“人类的头发就是红色的”，将来所有生成的图片都将是红色头发。</p><h2 id="提示词" tabindex="-1">提示词 <a class="header-anchor" href="#提示词" aria-label="Permalink to &quot;提示词&quot;">​</a></h2><h3 id="权重语法" tabindex="-1">权重语法 <a class="header-anchor" href="#权重语法" aria-label="Permalink to &quot;权重语法&quot;">​</a></h3><p>SD权重语法汇总如下：</p><table tabindex="0"><thead><tr><th>语法</th><th>说明</th></tr></thead><tbody><tr><td><code>prompt</code></td><td>没有任何符号，默认情况，1倍的权重</td></tr><tr><td><code>(prompt)</code></td><td>增加权重，1层为1.1倍，2层为1.21倍，3层为1.331倍</td></tr><tr><td><code>(prompt: x)</code></td><td>自定义权重，x最好控制在0.4~1.6之间。太小容易被忽视，太大容易拟合图像出错</td></tr><tr><td><code>[prompt]</code></td><td>降低权重。1层中括号为0.9倍，3层中括号为0.729倍</td></tr><tr><td><code>{prompt}</code></td><td>轻微增加权重。1层花括号为1.05倍，三层大括号为1.15倍</td></tr><tr><td><code>[prompt1 and prompt2]</code></td><td>prompt1和prompt2的混合，例如<code>[hot and dog]</code>表示在火中的狗</td></tr><tr><td><code>[prompt1_prompt2]</code></td><td>组合语法。比如<code>[coffee_cake]</code>表示咖啡蛋糕，既不是生成咖啡，也不是生成蛋糕。</td></tr><tr><td><code>[prompt:0.8]</code></td><td>在80%时刻才开始生成prompt，前面的时间跟该prompt无关</td></tr><tr><td><code>[prompt::0.8]</code></td><td>前80%时间段生成prompt，后面的时间跟该prompt无关</td></tr><tr><td><code>[prompt1:prompt2:0.8]</code></td><td>前80%的时间渲染prompt1，后20%的时间渲染prompt2</td></tr><tr><td><code>[prompt1 | prompt2 | prompt3]</code></td><td>循环往复，交替采样。如果你想把两种，将多种东西融合成一种，比如颜色渐变。</td></tr><tr><td><code>[prompt1 break prompt2] </code></td><td>在两个提示词中间写上“break”，作用就是把两个词完全隔离开，避免提示词之间的污染。</td></tr><tr><td><code>prompt1 AND prompt2</code></td><td>组合提示词，AND必须大写。例如，如果想要头发又有紫色又有绿色，则 purple hair AND green hair。</td></tr></tbody></table><h2 id="sora" tabindex="-1">Sora <a class="header-anchor" href="#sora" aria-label="Permalink to &quot;Sora&quot;">​</a></h2><h3 id="sora简介" tabindex="-1">Sora简介 <a class="header-anchor" href="#sora简介" aria-label="Permalink to &quot;Sora简介&quot;">​</a></h3><p>Sora 由OpenAI发布于2024年2月份，一经发布就轰动了世界。</p><p>Sora是一种文生视频大模型，但OpenAI的野心不止于此，官网的副标题是“Word Simulator（世界模拟器）”。因为Sora在使用大量的视频训练的过程中，学习到了客观世界的物理规律，例如行走、自由落体、视角变换、近大远小等。</p><h3 id="sora有望推动机器人的发展" tabindex="-1">Sora有望推动机器人的发展 <a class="header-anchor" href="#sora有望推动机器人的发展" aria-label="Permalink to &quot;Sora有望推动机器人的发展&quot;">​</a></h3><p>Sora推出之所以轰动，不是因为它是文生视频，而是因为它通过观看大量的视频，理解了真实世界的物理规律。这就是“涌现”能力，除了文生视频带动视频相关行业的颠覆，还有两个更重要的价值： 通过AGI的途径之一（多种模态）、 直接用在机器人上。</p><h2 id="svd" tabindex="-1">SVD <a class="header-anchor" href="#svd" aria-label="Permalink to &quot;SVD&quot;">​</a></h2><h3 id="stable-video-diffusion简介" tabindex="-1">Stable Video Diffusion简介 <a class="header-anchor" href="#stable-video-diffusion简介" aria-label="Permalink to &quot;Stable Video Diffusion简介&quot;">​</a></h3><p>Stable Video Diffusion，简称SVD，由StabilityAI发布于2023年11月，开源，能够生成帧率 14、分辨率 576x1024 的视频。</p><p>SVD-XT是SVD 的微调升级版，分辨率不变，但能够生成帧率 25 的视频；</p><h3 id="svd的训练过程" tabindex="-1">SVD的训练过程 <a class="header-anchor" href="#svd的训练过程" aria-label="Permalink to &quot;SVD的训练过程&quot;">​</a></h3><p>先搜集了5.8亿个视频剪辑。经过层层筛选，最后保留了1.5亿个视频片段的超高质量数据集。</p><p>SVD的训练分为三个主要步骤： 文生图预训练、 视频生成预训练、 高质量视频微调。</p><h2 id="svd配合comfyui" tabindex="-1">SVD配合ComfyUI <a class="header-anchor" href="#svd配合comfyui" aria-label="Permalink to &quot;SVD配合ComfyUI&quot;">​</a></h2><p><img src="/assets/ComfyUI-SVD.BsDJVUFI.png" alt="ComfyUI-SVD"></p><h1 id="transformer" tabindex="-1">Transformer <a class="header-anchor" href="#transformer" aria-label="Permalink to &quot;Transformer&quot;">​</a></h1><h2 id="transformer-源码" tabindex="-1">Transformer 源码 <a class="header-anchor" href="#transformer-源码" aria-label="Permalink to &quot;Transformer 源码&quot;">​</a></h2><div class="language-py vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">py</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> numpy </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.optim </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> optim</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> matplotlib.pyplot </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> make_batch</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(sentences):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    input_batch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [[src_vocab[n] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sentences[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].split()]]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    output_batch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [[tgt_vocab[n] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sentences[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].split()]]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    target_batch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [[tgt_vocab[n] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sentences[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].split()]]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.LongTensor(input_batch), torch.LongTensor(output_batch), torch.LongTensor(target_batch)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> get_sinusoid_encoding_table</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(n_position, d_model):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> cal_angle</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(position, hid_idx):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> position </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.power(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (hid_idx </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">//</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d_model)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> get_posi_angle_vec</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(position):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [cal_angle(position, hid_j) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> hid_j </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(d_model)]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    sinusoid_table </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.array([get_posi_angle_vec(pos_i) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pos_i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(n_position)])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    sinusoid_table[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.sin(sinusoid_table[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># dim 2i</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    sinusoid_table[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.cos(sinusoid_table[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">])  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># dim 2i+1</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.FloatTensor(sinusoid_table)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> get_attn_pad_mask</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(seq_q, seq_k):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    batch_size, len_q </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> seq_q.size()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    batch_size, len_k </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> seq_k.size()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # eq(zero) is PAD token</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    pad_attn_mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> seq_k.data.eq(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).unsqueeze(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># batch_size x 1 x len_k(=len_q), one is masking</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pad_attn_mask.expand(batch_size, len_q, len_k)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># batch_size x len_q x len_k</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> get_attn_subsequent_mask</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(seq):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    attn_shape </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [seq.size(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), seq.size(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), seq.size(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    subsequent_mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.triu(np.ones(attn_shape), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">k</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    subsequent_mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.from_numpy(subsequent_mask).byte()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> subsequent_mask</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> ScaledDotProductAttention</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(ScaledDotProductAttention, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, Q, K, V, attn_mask):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        scores </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.matmul(Q, K.transpose(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> np.sqrt(d_k) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        scores.masked_fill_(attn_mask, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Fills elements of self tensor with value where mask is one.</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Softmax(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)(scores)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        context </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.matmul(attn, V)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> context, attn</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MultiHeadAttention</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(MultiHeadAttention, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">W_Q</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(d_model, d_k </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n_heads)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">W_K</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(d_model, d_k </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n_heads)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">W_V</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(d_model, d_v </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n_heads)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(n_heads </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d_v, d_model)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.layer_norm </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.LayerNorm(d_model)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, Q, K, V, attn_mask):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        residual, batch_size </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Q, Q.size(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # (B, S, D) -proj-&gt; (B, S, D) -split-&gt; (B, S, H, W) -trans-&gt; (B, H, S, W)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        q_s </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.W_Q(Q).view(batch_size, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, n_heads, d_k).transpose(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># q_s: [batch_size x n_heads x len_q x d_k]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        k_s </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.W_K(K).view(batch_size, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, n_heads, d_k).transpose(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># k_s: [batch_size x n_heads x len_k x d_k]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        v_s </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.W_V(V).view(batch_size, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, n_heads, d_v).transpose(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># v_s: [batch_size x n_heads x len_k x d_v]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        attn_mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> attn_mask.unsqueeze(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).repeat(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, n_heads, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># attn_mask : [batch_size x n_heads x len_q x len_k]</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        context, attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        context </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> context.transpose(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).contiguous().view(batch_size, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, n_heads </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d_v) </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">            # context: [batch_size x len_q x n_heads * d_v]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear(context)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.layer_norm(output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> residual), attn </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># output: [batch_size x len_q x d_model]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> PoswiseFeedForwardNet</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(PoswiseFeedForwardNet, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.conv1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Conv1d(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_channels</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">d_model, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_channels</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">d_ff, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.conv2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Conv1d(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">in_channels</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">d_ff, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">out_channels</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">d_model, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">kernel_size</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.layer_norm </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.LayerNorm(d_model)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, inputs):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        residual </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> inputs </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># inputs : [batch_size, len_q, d_model]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.ReLU()(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.conv1(inputs.transpose(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.conv2(output).transpose(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.layer_norm(output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> residual)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> EncoderLayer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(EncoderLayer, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.enc_self_attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MultiHeadAttention()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.pos_ffn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PoswiseFeedForwardNet()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, enc_inputs, enc_self_attn_mask):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        enc_outputs, attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">            # enc_inputs to same Q,K,V</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        enc_outputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.pos_ffn(enc_outputs) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># enc_outputs: [batch_size x len_q x d_model]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> enc_outputs, attn</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> DecoderLayer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(DecoderLayer, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dec_self_attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MultiHeadAttention()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dec_enc_attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MultiHeadAttention()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.pos_ffn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PoswiseFeedForwardNet()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        dec_outputs, dec_self_attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        dec_outputs, dec_enc_attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        dec_outputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.pos_ffn(dec_outputs)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dec_outputs, dec_self_attn, dec_enc_attn</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">##### 编码器</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> Encoder</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(Encoder, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 将输入单词进行Embedding</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.src_emb </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Embedding(src_vocab_size, d_model) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># src_vocab_size：词表大小；d_model：嵌入维度</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 添加位置编码</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.pos_emb </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Embedding.from_pretrained(get_sinusoid_encoding_table(src_len</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, d_model),</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">freeze</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 前馈神经网络</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.layers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.ModuleList([EncoderLayer() </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> _ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(n_layers)])</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, enc_inputs): </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># enc_inputs : [batch_size x source_len]</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 词向量 和 位置编码进行相加</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        enc_outputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.src_emb(enc_inputs) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.pos_emb(torch.LongTensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]]))</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        #</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        enc_self_attn_mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> get_attn_pad_mask(enc_inputs, enc_inputs)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        enc_self_attns </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> []</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.layers:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            enc_outputs, enc_self_attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layer(enc_outputs, enc_self_attn_mask)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            enc_self_attns.append(enc_self_attn)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> enc_outputs, enc_self_attns</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> Decoder</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(Decoder, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.tgt_emb </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Embedding(tgt_vocab_size, d_model)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.pos_emb </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Embedding.from_pretrained(get_sinusoid_encoding_table(tgt_len</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, d_model),</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">freeze</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.layers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.ModuleList([DecoderLayer() </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> _ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(n_layers)])</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, dec_inputs, enc_inputs, enc_outputs): </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># dec_inputs : [batch_size x target_len]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        dec_outputs </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.tgt_emb(dec_inputs) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.pos_emb(torch.LongTensor([[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]]))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        dec_self_attn_pad_mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> get_attn_pad_mask(dec_inputs, dec_inputs)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        dec_self_attn_subsequent_mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> get_attn_subsequent_mask(dec_inputs)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        dec_self_attn_mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.gt((dec_self_attn_pad_mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dec_self_attn_subsequent_mask), </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        dec_enc_attn_mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> get_attn_pad_mask(dec_inputs, enc_inputs)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        dec_self_attns, dec_enc_attns </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [], []</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.layers:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            dec_outputs, dec_self_attn, dec_enc_attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            dec_self_attns.append(dec_self_attn)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            dec_enc_attns.append(dec_enc_attn)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dec_outputs, dec_self_attns, dec_enc_attns</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> Transformer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(Transformer, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 编码器</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.encoder </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Encoder()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 解码器</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.decoder </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Decoder()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 解码器最后的分类器，分类器的输入d_model是解码层每个token的输出维度大小，</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">            # 需要将其转为词表大小，再计算softmax；计算哪个词出现的概率最大</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.projection </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(d_model, tgt_vocab_size, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bias</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, enc_inputs, dec_inputs):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        #  Transformer的两个输入，一个是编码器的输入（源序列），一个是解码器的输入（目标序列）</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 其中，enc_inputs的大小应该是 [batch_size, src_len] ;  dec_inputs的大小应该是 [batch_size, dec_inputs]</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        源数据输入到encoder之后得到 enc_outputs, enc_self_attns；</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        enc_outputs是需要传给decoder的矩阵，表示源数据的表示特征</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        enc_self_attns表示单词之间的相关性矩阵</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        enc_outputs, enc_self_attns </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.encoder(enc_inputs)</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        decoder的输入数据包括三部分：</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        1. encoder得到的表示特征enc_outputs、</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        2. 解码器的输入dec_inputs（目标序列）、</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        3. 以及enc_inputs</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        dec_outputs, dec_self_attns, dec_enc_attns </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.decoder(dec_inputs, enc_inputs, enc_outputs)</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        将decoder的输出映射到词表大小，最后进行softmax输出即可</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        dec_logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.projection(dec_outputs) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># dec_logits : [batch_size x src_vocab_size x tgt_vocab_size]</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dec_logits.view(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, dec_logits.size(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)), enc_self_attns, dec_self_attns, dec_enc_attns</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> showgraph</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(attn):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> attn[</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].squeeze(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> attn.squeeze(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).data.numpy()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    fig </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> plt.figure(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">figsize</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(n_heads, n_heads)) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># [n_heads, n_heads]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ax </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> fig.add_subplot(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ax.matshow(attn, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">cmap</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;viridis&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ax.set_xticklabels([</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">sentences[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].split(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">fontdict</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;fontsize&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">14</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">rotation</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">90</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ax.set_yticklabels([</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">sentences[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">].split(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">fontdict</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;fontsize&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">14</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">})</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    plt.show()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __name__</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> ==</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;__main__&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 句子的输入部分</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    第一个句子 是 编码器的输入</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    第二个句子 是 解码器的输入</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    第三个句子 是 标签</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    P 可以理解为 编码器输入结束的字符（Padding填充字符）</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    S 可以理解为 Start</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    E 可以理解为 End</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    此外，需要注意的是，由于文本内容长度往往会不一致，因此在代码实现过程中，我们往往会设置一个最大长度max_length，</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    - 大于max_length的句子，多余的部分将会被裁剪</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    - 小于max_length的句子，缺少的部分将会被填充</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    sentences </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;ich mochte ein bier P&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;S i want a beer&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;i want a beer E&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Transformer Parameters</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Padding Should be Zero</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    src_vocab </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;P&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;ich&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;mochte&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;ein&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;bier&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    src_vocab_size </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(src_vocab)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    tgt_vocab </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;P&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;i&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;want&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;a&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;beer&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;S&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;E&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    number_dict </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {i: w </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i, w </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> enumerate</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(tgt_vocab)}</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    tgt_vocab_size </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> len</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(tgt_vocab)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    src_len </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 5</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> # length of source 输入长度</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    tgt_len </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 5</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> # length of target 解码端的输入长度</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    d_model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 512</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # Embedding Size  Embedding后的长度</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    d_ff </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2048</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # FeedForward dimension  前馈神经网络的中间维度</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    d_k </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> d_v </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 64</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # dimension of K(=Q), V</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    n_layers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 6</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # number of Encoder of Decoder Layer   Encoder和Decoder N的个数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    n_heads </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 8</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  # number of heads in Multi-Head Attention  多头注意力机制分为几个头</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> Transformer()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    criterion </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.CrossEntropyLoss()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> optim.Adam(model.parameters(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.001</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    enc_inputs, dec_inputs, target_batch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> make_batch(sentences)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> epoch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        optimizer.zero_grad()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        outputs, enc_self_attns, dec_self_attns, dec_enc_attns </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model(enc_inputs, dec_inputs)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> criterion(outputs, target_batch.contiguous().view(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Epoch:&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">%04d</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> %</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (epoch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">), </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;cost =&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:.6f</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.format(loss))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        loss.backward()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        optimizer.step()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # Test</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    predict, _, _, _ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model(enc_inputs, dec_inputs)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    predict </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> predict.data.max(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">keepdim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(sentences[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;-&gt;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, [number_dict[n.item()] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> predict.squeeze()])</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;first head of last state enc_self_attns&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    showgraph(enc_self_attns)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;first head of last state dec_self_attns&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    showgraph(dec_self_attns)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;first head of last state dec_enc_attns&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    showgraph(dec_enc_attns)</span></span></code></pre></div></div></div></main><footer class="VPDocFooter" data-v-fa71b28f data-v-c87fa0c5><!--[--><!--]--><!----><!----></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"ai_comfyui.md\":\"Kg4PSJaP\",\"ai_index.md\":\"5X2inuI_\",\"css_index.md\":\"C_Wf1mPU\",\"electron_index.md\":\"B8u2xrkf\",\"index.md\":\"D1ke_gzH\",\"javascript_javascript.md\":\"XIcbUa9Q\",\"linux_index.md\":\"CBEe9bkR\",\"node.js_index.md\":\"jeRUt9AZ\",\"office.md\":\"CXpyMw4_\",\"python_index.md\":\"C9zwYP3U\",\"react-native_index.md\":\"C7w4ig0v\",\"react_index.md\":\"DPB8l62M\",\"webrtc_index.md\":\"Dknl8VMy\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"VitePress\",\"description\":\"A VitePress site\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>